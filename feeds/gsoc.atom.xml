<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>All Day I Dream About Science</title><link href="http://siddhantsci.org/" rel="alternate"></link><link href="/feeds/gsoc.atom.xml" rel="self"></link><id>http://siddhantsci.org/</id><updated>2015-07-31T19:53:52+00:00</updated><entry><title>Telerobotics and Bodytracking - The Rendezvous</title><link href="http://siddhantsci.org/blog/2015/07/31/telerobotics-and-bodytracking-the-rendezvous/" rel="alternate"></link><updated>2015-07-31T19:53:52+00:00</updated><author><name>Siddhant Shrivastava</name></author><id>tag:siddhantsci.org,2015-07-31:blog/2015/07/31/telerobotics-and-bodytracking-the-rendezvous/</id><summary type="html">&lt;p&gt;Hi! The past week was a refreshingly positive one. I was able to solve some of the insidious issues that were plaguing the efforts that I was putting in last week.&lt;/p&gt;
&lt;h2&gt;Virtual Machine Networking issues Solved!&lt;/h2&gt;
&lt;p&gt;I was able to use the Tango server across the Windows 7 Virtual Machine and the Tango Host on my Ubuntu 14.04 Host Machine. The proper Networking mode for this turns out to be &lt;strong&gt;Bridged Networking mode&lt;/strong&gt; which basically tunnels a connection between the Virtual Machine and the host.&lt;/p&gt;
&lt;p&gt;In the bridged mode, the Virtual Machine exposes a Virtual Network interface with its own IP Address and Networking stack. In my case it was &lt;code&gt;vm8&lt;/code&gt; with an IP Address different from the IP Address patterns that were used by the &lt;em&gt;real&lt;/em&gt; Ethernet and WiFi Network Interface Cards. Using bridged mode, I was able to maintain the Tango Device Database server on Ubuntu and use Vito's Bodytracking device on Windows. The Virtual Machine didn't slow down things by any magnitude while communicating across the Tango devices.&lt;/p&gt;
&lt;p&gt;This image explains what I'm talking about -&lt;/p&gt;
&lt;p&gt;&lt;img alt="Jive on Windows and Ubuntu machines" src="http://siddhantsci.org/images/jive_windows_ubuntu.png" /&gt;&lt;/p&gt;
&lt;p&gt;In bridged mode, I chose the IP Address on the host which corresponds to the Virtual Machine interface - &lt;code&gt;vmnet8&lt;/code&gt; in my case. I used the &lt;code&gt;vmnet8&lt;/code&gt; interface on Ubuntu and a similar interface on the Windows Virtual Machine. I read quite a bit about how Networking works in Virtual Machines and was fascinated by the Virtualization in place.&lt;/p&gt;
&lt;h2&gt;Bodytracking meets Telerobotics&lt;/h2&gt;
&lt;p&gt;With Tango up and running, I had to ensure that &lt;a href="https://vigentile.wordpress.com/2015/07/31/enhancement-of-kinect-integration-in-v-eras-fifth-report/"&gt;Vito's Bodytracking application&lt;/a&gt; works on the Virtual Machine. To that end, I installed &lt;em&gt;Kinect for Windows SDK&lt;/em&gt;, &lt;em&gt;Kinect Developer Tools&lt;/em&gt;, &lt;em&gt;Visual Python&lt;/em&gt;, &lt;em&gt;Tango-Controls&lt;/em&gt;, and &lt;em&gt;PyTango&lt;/em&gt;. Setting a new &lt;em&gt;virtual&lt;/em&gt; machine up mildly slowed me down but was a necessary step in the development.&lt;/p&gt;
&lt;p&gt;Once I had that bit running, I was able to visualize the &lt;strong&gt;simulated Martian Motivity walk done in Innsbruck &lt;/strong&gt; in a training station. The Bodytracking server created by Vito &lt;em&gt;published&lt;/em&gt; events corresponding to the &lt;code&gt;moves&lt;/code&gt; attribute which is a list of the following two metrics -&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Position&lt;/li&gt;
&lt;li&gt;Orientation&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I was able to read the attributes that the Bodytracking device was publishing by &lt;strong&gt;subscribing&lt;/strong&gt; to Event Changes to that attribute.  This is done in the following way -&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="n"&gt;TRIGGER&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
        &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="n"&gt;Subscribe&lt;/span&gt; &lt;span class="n"&gt;to&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;moves&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt; &lt;span class="n"&gt;event&lt;/span&gt; &lt;span class="n"&gt;from&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;Bodytracking&lt;/span&gt; &lt;span class="n"&gt;interface&lt;/span&gt;
        &lt;span class="n"&gt;moves_event&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;device_proxy&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subscribe_event&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
                                                                                 &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;moves&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                                                                  &lt;span class="n"&gt;PyTango&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;EventType&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CHANGE_EVENT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                                                                  &lt;span class="n"&gt;cb&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;[])&lt;/span&gt;
        &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="n"&gt;Wait&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;at&lt;/span&gt; &lt;span class="n"&gt;least&lt;/span&gt; &lt;span class="n"&gt;REFRESH_RATE&lt;/span&gt; &lt;span class="n"&gt;Seconds&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;next&lt;/span&gt; &lt;span class="n"&gt;callback&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;
        &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sleep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;REFRESH_RATE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This ensures that the Subscriber doesn't exhaust the polled attributes at a rate faster than they are published. In that unfortunate case, an &lt;code&gt;EventManagerException&lt;/code&gt; occurs which must be handled properly.&lt;/p&gt;
&lt;p&gt;Note the &lt;code&gt;cb&lt;/code&gt; attribute, it refers to the Callback function that is triggered when an Event change occurs. The callback function is responsible for reading and processing the attributes.&lt;/p&gt;
&lt;p&gt;The processing part in our case is the core of the &lt;strong&gt;Telerobotics-Bodytracking interface&lt;/strong&gt;. It acts as the intermediary between Telerobotics  and Bodytracking - converting the &lt;em&gt;position&lt;/em&gt;, and &lt;em&gt;orientation&lt;/em&gt; values to &lt;strong&gt;linear and angular velocity&lt;/strong&gt; that Husky can understand. I use a high-performance container from the &lt;code&gt;collections&lt;/code&gt; class known as &lt;code&gt;deque&lt;/code&gt;. It can act both as a stack and a queue using &lt;code&gt;deque.append&lt;/code&gt;, &lt;code&gt;deque.appendleft&lt;/code&gt;, &lt;code&gt;deque.pop&lt;/code&gt;, &lt;code&gt;deque.popleft&lt;/code&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;To calculate velocity, I compute the differences between consecutive events and their corresponding timestamps. The events are stored in a &lt;code&gt;deque&lt;/code&gt;, popped when necessary and subtracted from the current event values&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;For instance this is how &lt;strong&gt;linear velocity&lt;/strong&gt; processing takes place -&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;  &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="n"&gt;Position&lt;/span&gt; &lt;span class="n"&gt;and&lt;/span&gt; &lt;span class="n"&gt;Linear&lt;/span&gt; &lt;span class="n"&gt;Velocity&lt;/span&gt; &lt;span class="n"&gt;Processing&lt;/span&gt;
  &lt;span class="n"&gt;position_previous&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;position_events&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pop&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
  &lt;span class="n"&gt;position_current&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;position&lt;/span&gt;
  &lt;span class="n"&gt;linear_displacement&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;position_current&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;position_previous&lt;/span&gt;
  &lt;span class="n"&gt;linear_speed&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;linear_displacement&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;time_delta&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;ROS-Telerobotics Interface&lt;/h2&gt;
&lt;p&gt;We are halfway through the Telerobotics-Bodytracking architecture. Once the velocities are obtained, we have everything we need to send to ROS. The challenge here is to use velocities which ROS and the Husky UGV can understand. The messages are published ot ROS &lt;em&gt;only&lt;/em&gt; when there is some change in the velocity. This has the added advantage of minimzing communication between ROS and Tango. When working with multiple distributed systems, it is always wise to keep the communication between them minimial. That's what I've aimed to do. I'll be enhacing the interface even further by adding Trigger Overrides in case of an emergency situation. The speeds currently are not ROS-friendly. I am writing a high-pass and low-pass filter to limit the velocities to what Husky can sustain. Vito and I will be refining the User Step estimation and the corresponding Robot movements respectively.&lt;/p&gt;
&lt;p&gt;GSoC is only becoming more exciting. I'm certain that I will be contributing to this project after GSoC as well. The Telerobotics scenario is full of possibilities, most of which I've tried to cover in my GSoC proposal.&lt;/p&gt;
&lt;p&gt;I'm back to my university now and it has become hectic but enjoyably challenging to complete this project. My next post will hopefully be a culmination of the Telerobotics/Bodytracking interface and the integration of 3D streaming with Oculus Rift Virtual Reality.&lt;/p&gt;
&lt;p&gt;Ciao!&lt;/p&gt;</summary><category term="GSoC"></category><category term="Python"></category><category term="PSF"></category><category term="computers"></category><category term="science"></category><category term="exploration"></category><category term="space"></category><category term="mars"></category><category term="IMS"></category><category term="Italian Mars Society"></category></entry><entry><title>Virtual Machines + Virtual Reality = Real Challenges!</title><link href="http://siddhantsci.org/blog/2015/07/24/virtual-machines-virtual-reality-real-challenges/" rel="alternate"></link><updated>2015-07-24T19:53:52+00:00</updated><author><name>Siddhant Shrivastava</name></author><id>tag:siddhantsci.org,2015-07-24:blog/2015/07/24/virtual-machines-virtual-reality-real-challenges/</id><summary type="html">&lt;p&gt;Hi! For the past couple of weeks, I've been trying to get a lot of things to work. Linux and Computer Networks seem to like me so much that they ensure my attention throughout the course of this program. This time it was dynamic libraries, Virtual Machine Networking, Docker Containers, Head-mounted display errors and so on.&lt;/p&gt;
&lt;p&gt;A brief discussion about these:&lt;/p&gt;
&lt;h2&gt;Dynamic Libraries, Oculus Rift, and Python Bindings&lt;/h2&gt;
&lt;p&gt;Using the open-source Python bindings for the &lt;strong&gt;Oculus SDK&lt;/strong&gt; available &lt;a href="https://github.com/jherico/python-ovrsdk"&gt;here&lt;/a&gt;, Franco and I ran into a problem -&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nx"&gt;ImportError&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nb"&gt;root&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;/&lt;/span&gt;&lt;span class="nx"&gt;oculusvr&lt;/span&gt;&lt;span class="p"&gt;/&lt;/span&gt;&lt;span class="nx"&gt;linux&lt;/span&gt;&lt;span class="na"&gt;-x86&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;64&lt;/span&gt;&lt;span class="p"&gt;/&lt;/span&gt;&lt;span class="nx"&gt;libOculusVR.so&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;undefined&lt;/span&gt; &lt;span class="nx"&gt;symbol&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nx"&gt;glXMakeCurrent&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;To get to the root of the problem, I tried to list all dependencies of the &lt;strong&gt;shared object file&lt;/strong&gt; -&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;  &lt;span class="n"&gt;linux&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;vdso&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="mf"&gt;.1&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt;  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mh"&gt;0x00007ffddb388000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;librt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="mf"&gt;.1&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;lib&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;linux&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;gnu&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;librt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="mf"&gt;.1&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mh"&gt;0x00007f6205e1d000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;libpthread&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="mf"&gt;.0&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;lib&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;linux&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;gnu&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;libpthread&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="mf"&gt;.0&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mh"&gt;0x00007f6205bff000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;libX11&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="mf"&gt;.6&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;usr&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;lib&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;linux&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;gnu&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;libX11&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="mf"&gt;.6&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mh"&gt;0x00007f62058ca000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;libXrandr&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="mf"&gt;.2&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;usr&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;lib&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;linux&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;gnu&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;libXrandr&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="mf"&gt;.2&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mh"&gt;0x00007f62056c0000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;libstdc&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="mf"&gt;.6&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;usr&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;lib&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;linux&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;gnu&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;libstdc&lt;/span&gt;&lt;span class="o"&gt;++&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="mf"&gt;.6&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mh"&gt;0x00007f62053bc000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;libm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="mf"&gt;.6&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;lib&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;linux&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;gnu&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;libm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="mf"&gt;.6&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mh"&gt;0x00007f62050b6000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;libgcc_s&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="mf"&gt;.1&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;lib&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;linux&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;gnu&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;libgcc_s&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="mf"&gt;.1&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mh"&gt;0x00007f6204ea0000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;libc&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="mf"&gt;.6&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;lib&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;linux&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;gnu&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;libc&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="mf"&gt;.6&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mh"&gt;0x00007f6204adb000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;lib64&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;ld&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;linux&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;x86&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;64.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="mf"&gt;.2&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mh"&gt;0x00007f6206337000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;libxcb&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="mf"&gt;.1&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;usr&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;lib&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;linux&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;gnu&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;libxcb&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="mf"&gt;.1&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mh"&gt;0x00007f62048bc000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;libdl&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="mf"&gt;.2&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;lib&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;linux&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;gnu&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;libdl&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="mf"&gt;.2&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mh"&gt;0x00007f62046b8000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;libXext&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="mf"&gt;.6&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;usr&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;lib&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;linux&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;gnu&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;libXext&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="mf"&gt;.6&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mh"&gt;0x00007f62044a6000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;libXrender&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="mf"&gt;.1&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;usr&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;lib&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;linux&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;gnu&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;libXrender&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="mf"&gt;.1&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mh"&gt;0x00007f620429c000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;libXau&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="mf"&gt;.6&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;usr&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;lib&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;linux&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;gnu&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;libXau&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="mf"&gt;.6&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mh"&gt;0x00007f6204098000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;libXdmcp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="mf"&gt;.6&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;usr&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;lib&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;x86_64&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;linux&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;gnu&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;libXdmcp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="mf"&gt;.6&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mh"&gt;0x00007f6203e92000&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;undefined&lt;/span&gt; &lt;span class="n"&gt;symbol&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;glXMakeCurrent&lt;/span&gt;  &lt;span class="p"&gt;(.&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;libOculusVR&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;undefined&lt;/span&gt; &lt;span class="n"&gt;symbol&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;glEnable&lt;/span&gt;  &lt;span class="p"&gt;(.&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;libOculusVR&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;undefined&lt;/span&gt; &lt;span class="n"&gt;symbol&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;glFrontFace&lt;/span&gt; &lt;span class="p"&gt;(.&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;libOculusVR&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;undefined&lt;/span&gt; &lt;span class="n"&gt;symbol&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;glDisable&lt;/span&gt; &lt;span class="p"&gt;(.&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;libOculusVR&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;undefined&lt;/span&gt; &lt;span class="n"&gt;symbol&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;glClear&lt;/span&gt; &lt;span class="p"&gt;(.&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;libOculusVR&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;undefined&lt;/span&gt; &lt;span class="n"&gt;symbol&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;glGetError&lt;/span&gt;  &lt;span class="p"&gt;(.&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;libOculusVR&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;undefined&lt;/span&gt; &lt;span class="n"&gt;symbol&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;glXDestroyContext&lt;/span&gt; &lt;span class="p"&gt;(.&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;libOculusVR&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;undefined&lt;/span&gt; &lt;span class="n"&gt;symbol&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;glXCreateContext&lt;/span&gt;  &lt;span class="p"&gt;(.&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;libOculusVR&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;undefined&lt;/span&gt; &lt;span class="n"&gt;symbol&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;glClearColor&lt;/span&gt;  &lt;span class="p"&gt;(.&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;libOculusVR&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;undefined&lt;/span&gt; &lt;span class="n"&gt;symbol&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;glXGetCurrentContext&lt;/span&gt;  &lt;span class="p"&gt;(.&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;libOculusVR&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;undefined&lt;/span&gt; &lt;span class="n"&gt;symbol&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;glXSwapBuffers&lt;/span&gt;  &lt;span class="p"&gt;(.&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;libOculusVR&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;undefined&lt;/span&gt; &lt;span class="n"&gt;symbol&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;glColorMask&lt;/span&gt; &lt;span class="p"&gt;(.&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;libOculusVR&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;undefined&lt;/span&gt; &lt;span class="n"&gt;symbol&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;glBlendFunc&lt;/span&gt; &lt;span class="p"&gt;(.&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;libOculusVR&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;undefined&lt;/span&gt; &lt;span class="n"&gt;symbol&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;glBindTexture&lt;/span&gt; &lt;span class="p"&gt;(.&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;libOculusVR&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;undefined&lt;/span&gt; &lt;span class="n"&gt;symbol&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;glDepthMask&lt;/span&gt; &lt;span class="p"&gt;(.&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;libOculusVR&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;undefined&lt;/span&gt; &lt;span class="n"&gt;symbol&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;glDeleteTextures&lt;/span&gt;  &lt;span class="p"&gt;(.&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;libOculusVR&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;undefined&lt;/span&gt; &lt;span class="n"&gt;symbol&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;glGetIntegerv&lt;/span&gt; &lt;span class="p"&gt;(.&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;libOculusVR&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;undefined&lt;/span&gt; &lt;span class="n"&gt;symbol&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;glXGetCurrentDrawable&lt;/span&gt; &lt;span class="p"&gt;(.&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;libOculusVR&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;undefined&lt;/span&gt; &lt;span class="n"&gt;symbol&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;glDrawElements&lt;/span&gt;  &lt;span class="p"&gt;(.&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;libOculusVR&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;undefined&lt;/span&gt; &lt;span class="n"&gt;symbol&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;glTexImage2D&lt;/span&gt;  &lt;span class="p"&gt;(.&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;libOculusVR&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;undefined&lt;/span&gt; &lt;span class="n"&gt;symbol&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;glXGetClientString&lt;/span&gt;  &lt;span class="p"&gt;(.&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;libOculusVR&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;undefined&lt;/span&gt; &lt;span class="n"&gt;symbol&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;glDrawArrays&lt;/span&gt;  &lt;span class="p"&gt;(.&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;libOculusVR&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;undefined&lt;/span&gt; &lt;span class="n"&gt;symbol&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;glGetString&lt;/span&gt; &lt;span class="p"&gt;(.&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;libOculusVR&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;undefined&lt;/span&gt; &lt;span class="n"&gt;symbol&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;glXGetProcAddress&lt;/span&gt; &lt;span class="p"&gt;(.&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;libOculusVR&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;undefined&lt;/span&gt; &lt;span class="n"&gt;symbol&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;glViewport&lt;/span&gt;  &lt;span class="p"&gt;(.&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;libOculusVR&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;undefined&lt;/span&gt; &lt;span class="n"&gt;symbol&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;glTexParameteri&lt;/span&gt; &lt;span class="p"&gt;(.&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;libOculusVR&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;undefined&lt;/span&gt; &lt;span class="n"&gt;symbol&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;glGenTextures&lt;/span&gt; &lt;span class="p"&gt;(.&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;libOculusVR&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;undefined&lt;/span&gt; &lt;span class="n"&gt;symbol&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;glFinish&lt;/span&gt;  &lt;span class="p"&gt;(.&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;libOculusVR&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This clearly implied one thing - &lt;strong&gt;libGL&lt;/strong&gt; was not being linked. My task then was to &lt;em&gt;somehow&lt;/em&gt; link libGL to the SO file that came with the Python Bindings. I tried out the following two options -&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Creating my own bindings&lt;/strong&gt;: Tried to regenerate the SO file from the Oculus C SDK by using the amazing &lt;a href="https://github.com/davidjamesca/ctypesgen"&gt;Python Ctypesgen&lt;/a&gt;. This method didn't work out as I couldn't resolve the &lt;em&gt;header&lt;/em&gt; files that are requied by &lt;em&gt;Ctypesgen&lt;/em&gt;. Nevertheless, I learned how to create Python Bindings and that is a huge take-away from the exercise. I had always wondered how Python interfaces are created out of programs written in other languages.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Making the existing shared object file believe that it is linked to libGL&lt;/strong&gt;: So here's what I did - after a lot of searching, I found the nifty little environment variable that worked wonders for our Oculus development - &lt;strong&gt;LD_PRELOAD&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As &lt;a href="https://rafalcieslak.wordpress.com/2013/04/02/dynamic-linker-tricks-using-ld_preload-to-cheat-inject-features-and-investigate-programs/"&gt;this&lt;/a&gt; and &lt;a href="http://blog.chaselambda.com/2014/11/28/how-tmux-starts-up-an-adventure-with-linux-tools-updated.html"&gt;this&lt;/a&gt; articles delineate the power of LD_PRELOAD, it is possible to force-load a dynamically linked shared object in the memory.
If you set LD_PRELOAD to the path of a shared object, that file will be loaded before any other library (including the C runtime, libc.so). For example, to run &lt;code&gt;ls&lt;/code&gt; with your special malloc() implementation, do this:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$ LD_PRELOAD=/path/to/my/malloc.so /bin/ls&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Thus, the solution to my problem was to place this in the &lt;code&gt;.bashrc&lt;/code&gt; file -&lt;/p&gt;
&lt;p&gt;&lt;code&gt;LD_PRELOAD="/usr/lib/x86_64-linux-gnu/libGL.so"&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This allowed Franco to create the Oculus Test Tango server and ensured that our Oculus Rift development efforts continue with gusto.&lt;/p&gt;
&lt;h2&gt;ROS and Autonomous Navigation&lt;/h2&gt;
&lt;p&gt;On the programming side, I've been playing around with &lt;code&gt;actionlib&lt;/code&gt; to interface Bodytracking with Telerobotics. I have created a simple walker script which provides a certain degree of autonomy to the robot and avoids collissions with objects to override human teleoperation commands. An obstacle could be a Martian rock in a simulated environment or an uneven terrain with a possible ditch ahead. To achieve this, I use the &lt;code&gt;LaserScan&lt;/code&gt; message and check for the range readings at frequent intervals. The &lt;em&gt;LIDAR&lt;/em&gt; readings ensure that the robot is in one of the following states -&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Approaching an obstacle&lt;/li&gt;
&lt;li&gt;Going away from an obstacle&lt;/li&gt;
&lt;li&gt;Hitting an obstacle&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The state can be inferred from the LaserScan Messages. A ROS Action Server then waits for one of these events to happen and triggers the callback which tells the robot to stop, turn and continue.&lt;/p&gt;
&lt;h2&gt;Windows and PyKinect&lt;/h2&gt;
&lt;p&gt;In order to run Vito's bodytracking code, I needed a Windows installation. Running into problems with a 32-bit Windows 7 Virtual Machine image I had, I needed to reinstall and use a 64-bits Virtual Machine image. I installed all the dependencies to run the bodytracking code. I am still stuck with Networking modes between the Virtual Machine and the Host machine. The TANGO host needs to be configured correctly to allow the TANGO_MASTER to point to the host and the TANGO_HOST to the virtual machine.&lt;/p&gt;
&lt;h2&gt;Docker and Qt Apps&lt;/h2&gt;
&lt;p&gt;Qt applications don't seem to work with sharing the display in a Docker container. The way out is to create users in the Docker container which I'm currently doing. I'll enable VNC and X-forwarding to allow the ROS Qt applications to work so that the other members of the Italian Mars Society can use the Docker container directly.&lt;/p&gt;
&lt;h2&gt;Gazebo Mars model&lt;/h2&gt;
&lt;p&gt;I took a brief look at the 3D models of Martial terrain available for free use on the Internet. I'll be trying to obtain the Gale Crater region and represent it in Gazebo to drive the Husky in a Martian Terrain.&lt;/p&gt;
&lt;h2&gt;Documentation week!&lt;/h2&gt;
&lt;p&gt;In addition to strong-arming my CS concepts against the Networking and Linux issues that loom over the project currently, I updated and added documentation for the modules developed so far.&lt;/p&gt;
&lt;p&gt;Hope the next post explains how I solved the problems described in this post. Ciao!&lt;/p&gt;</summary><category term="GSoC"></category><category term="Python"></category><category term="PSF"></category><category term="computers"></category><category term="science"></category><category term="exploration"></category><category term="space"></category><category term="mars"></category><category term="IMS"></category><category term="Italian Mars Society"></category></entry><entry><title>Streamed away (in Real-Time)!</title><link href="http://siddhantsci.org/blog/2015/07/16/streamed-away-in-real-time/" rel="alternate"></link><updated>2015-07-16T19:53:52+00:00</updated><author><name>Siddhant Shrivastava</name></author><id>tag:siddhantsci.org,2015-07-16:blog/2015/07/16/streamed-away-in-real-time/</id><summary type="html">&lt;p&gt;Hi! This post is &lt;em&gt;all&lt;/em&gt; about &lt;strong&gt;Video Streaming and Cameras&lt;/strong&gt; :-) If you've wondered how services like YouTube Live or twitch.tv work, then this post is for you. After the &lt;em&gt;Innsbruck experiments&lt;/em&gt; and &lt;a href="http://siddhantsci.org/blog/2015/07/08/remote-tests-in-telerobotics/"&gt;Remote tests in Telerobotics&lt;/a&gt;, it was time for me to create a full-fledged Real Time Video Streaming solution for the ERAS project. After a lot of frustration and learning, I've been able to achieve the following milestones - &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Stream losslessly from a single camera in real-time to a Blender Game Engine instance.&lt;/li&gt;
&lt;li&gt;Create example Blender projects to test &lt;em&gt;multiple video sources&lt;/em&gt; streaming over a network.&lt;/li&gt;
&lt;li&gt;Record a &lt;strong&gt;live stream&lt;/strong&gt; from a &lt;strong&gt;stereoscopic camera&lt;/strong&gt; into a side-by-side video encoded on the fly. &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;It's going to be a very long post as I've been playing around with lots of video streaming stuff. All this experience has turned me into a confident Multimedia streamer.&lt;/p&gt;
&lt;h2&gt;Why am I doing this?&lt;/h2&gt;
&lt;p&gt;Integrating &lt;em&gt;Augmented&lt;/em&gt; and &lt;em&gt;Virtual Reality&lt;/em&gt; requires one to know the nitty-gritty of &lt;strong&gt;Multimedia Streaming&lt;/strong&gt;. This week was spent in learning and tinkering with the various options provided by &lt;a href="https://ffmpeg.org/"&gt;FFmpeg&lt;/a&gt; and &lt;a href="linuxtv.org/downloads/v4l-dvb-apis/"&gt;Video4Linux2&lt;/a&gt;. One of the aims of the Telerobotics project is to allow streaming of Rover Camera input to the Astronaut's Head-Mounted Device (&lt;strong&gt;Minoru 3D&lt;/strong&gt; camera and &lt;strong&gt;Oculus Rift&lt;/strong&gt; in my case). The streamed video has multiple uses -&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;It is used by the various Tango servers (Planning, Vision, Telerobotics, etc) and processed to obtain Semantic relationships between objects in the Martian environment.&lt;/li&gt;
&lt;li&gt;The video, in addition to the LIDAR and other sensing devices are the interface of the Human world in the ERAS habitat on Mars. The video stream provides a window to Mars.&lt;/li&gt;
&lt;li&gt;The real-time stream helps the astronaut and the simulated astronaut to guide the rover and the simulated rover around on Mars.&lt;/li&gt;
&lt;li&gt;Streaming is an integral component of both ERAS and V-ERAS which we at the Italian Mars Society are currently working on. &lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Initial Impressions&lt;/h2&gt;
&lt;p&gt;When I started with 3D streaming, it &lt;em&gt;appeared&lt;/em&gt; easy. "I did it with a single camera, two cameras can't be a huge deal, right!". &lt;em&gt;I had never been so wrong&lt;/em&gt;. I found myself stuck in the usual embedded device vs the Linux kernel interface -&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The hardware of desktop machines are unsuitable for Streaming applications. &lt;/li&gt;
&lt;li&gt;The Kernel is not configured to use multiple webcams&lt;/li&gt;
&lt;li&gt;This results in lots of &lt;strong&gt;memory-related&lt;/strong&gt; errors - &lt;code&gt;insufficient memory&lt;/code&gt;, &lt;code&gt;rt_underflow&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To tweak the Minoru camera and strike an optimum settings agreement with this cute little stereo camera, I began to dig into the core software components involved -&lt;/p&gt;
&lt;h2&gt;Video4Linux2 saves the day!&lt;/h2&gt;
&lt;p&gt;The Video4Linux is an important driver framework which makes it possible for Linux users to use Video Capture devices (webcams and streaming equipment). It supports multiple features. The ones that this project is concerned with are -&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Video Capture/Output and Tuning (&lt;code&gt;/dev/videoX&lt;/code&gt;, streaming and control)&lt;/li&gt;
&lt;li&gt;Video Capture and Output overlay (&lt;code&gt;/dev/videoX&lt;/code&gt;, control)&lt;/li&gt;
&lt;li&gt;Memory-to-Memory (Codec) devices (&lt;code&gt;/dev/videoX&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="https://archive.fosdem.org/2014/schedule/event/v4l_intro/"&gt;These slides&lt;/a&gt; by Hans Verkuil (Cisco Systems) are and informative entry point for understanding how Video4Linux works.&lt;/p&gt;
&lt;p&gt;The different Streaming Modes supported by Video4Linux are -&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Read/Write (&lt;strong&gt;Supported by Minoru&lt;/strong&gt;) &lt;/li&gt;
&lt;li&gt;Memory Mapped Streaming I/O (&lt;strong&gt;Supported by Minoru&lt;/strong&gt;)&lt;/li&gt;
&lt;li&gt;User Pointer Streaming I/O&lt;/li&gt;
&lt;li&gt;DMA (Direct Memory Access) Buffer Streaming I/O&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The take-away from Video4Linux is understanding how streaming works. So a Stream requires the following - queue setup, preparing the buffer, start streaming, stop streaming, wait to prepare, wait to finish, compression and encoding of the input stream, transmission/feeding on a channel, decompression and decoding the received stream, and facilities for playback and time-seek.&lt;/p&gt;
&lt;p&gt;The Qt frontend to &lt;code&gt;v4l2&lt;/code&gt; made me realize where the problem with the camera lied -&lt;/p&gt;
&lt;p&gt;&lt;img alt="Qv4l2 Minoru" src="http://siddhantsci.org/images/minoru-qv4l2.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;video4linux2&lt;/code&gt; specification allows for querying and configuring &lt;strong&gt;everything&lt;/strong&gt; about Video Capture Cards. The nifty command-line utitlity &lt;code&gt;v4l2-ctl&lt;/code&gt; is a lifesaver while debugging cameras.&lt;/p&gt;
&lt;p&gt;For instance, with the Stereo Camera connected, &lt;code&gt;`v4l2-ctl --list-devices&lt;/code&gt; gives -&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;Vimicro&lt;/span&gt; &lt;span class="n"&gt;USB2&lt;/span&gt;&lt;span class="mf"&gt;.0&lt;/span&gt; &lt;span class="n"&gt;PC&lt;/span&gt; &lt;span class="n"&gt;Camera&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;usb&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mo"&gt;0000&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mo"&gt;00&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mf"&gt;14.0&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
        &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;video1&lt;/span&gt;

&lt;span class="n"&gt;Vimicro&lt;/span&gt; &lt;span class="n"&gt;USB2&lt;/span&gt;&lt;span class="mf"&gt;.0&lt;/span&gt; &lt;span class="n"&gt;PC&lt;/span&gt; &lt;span class="n"&gt;Camera&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;usb&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mo"&gt;0000&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mo"&gt;00&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mf"&gt;14.0&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
        &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;video2&lt;/span&gt;

&lt;span class="n"&gt;WebCam&lt;/span&gt; &lt;span class="n"&gt;SC&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;13&lt;/span&gt;&lt;span class="n"&gt;HDL11939N&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;usb&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mo"&gt;0000&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mo"&gt;00&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="mf"&gt;.0&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;1.4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
        &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;video0&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;v4l2&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;ctl&lt;/span&gt; &lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="n"&gt;list&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;frameintervals&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;640&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;480&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;pixelformat&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;YUYV&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;gives&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;ioctl&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;VIDIOC_ENUM_FRAMEINTERVALS&lt;/span&gt;
        &lt;span class="n"&gt;Interval&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Discrete&lt;/span&gt; &lt;span class="mf"&gt;0.033&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;30.000&lt;/span&gt; &lt;span class="n"&gt;fps&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;Interval&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Discrete&lt;/span&gt; &lt;span class="mf"&gt;0.067&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;15.000&lt;/span&gt; &lt;span class="n"&gt;fps&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This means that I've to use one of these settings for getting input from the camera, and then transcode them into the desired stream characteristics.&lt;/p&gt;
&lt;h2&gt;Knowing your stereoscopic Camera&lt;/h2&gt;
&lt;p&gt;&lt;img alt="Stereo" src="http://siddhantsci.org/images/stereo-1.png" /&gt;&lt;/p&gt;
&lt;p&gt;VLC carefully configured to stream the Left and Right Minoru Cameras/&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.minoru3d.com/"&gt;Minoru 3D&lt;/a&gt; webcam uses the following &lt;em&gt;Color Spaces&lt;/em&gt; -&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;RGB3&lt;/li&gt;
&lt;li&gt;YU12&lt;/li&gt;
&lt;li&gt;YV12&lt;/li&gt;
&lt;li&gt;YUYV&lt;/li&gt;
&lt;li&gt;BGR3&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Explanations ahead...&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;When colors meet computers and humans&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Color Spaces are models of 'Color Organization' that enable reproducible representations of color in different media (analog, digital). Color is a human subjective visual perceptual property. Recursing these definitions on Wikipedia took me back to Middle School. Color is a physical (observable and measurable) property. The way us humans see it is not the same as a color sensing photodiodes see it and the computer monitors reproduce it. Translating color from one base to another requires a data structure known as the &lt;strong&gt;color space&lt;/strong&gt;. The signals from the webcam are encoded into one of the color spaces. Just in case you're wondering - YUV model describes colors in terms of a &lt;strong&gt;Luma (luminance)&lt;/strong&gt; component and two chrominance components (U and V). The 2-D UV plane can describe all colors. YUV can be converted into RGB and vice-versa. The YUV422 data format shares U and V values between two pixels. As a result, these values are transmitted to the PC image buffer only once for every two pixels, resulting in an average transmission rate of 16 bits per pixel.
Capturing on the YUV 4:2:2 format is more efficient than RGB formats whereas color reproduction on a pixel array is more convenient via RGB.
For the purposes of Video Streaming from a Stereo Camera System like Minoru, using a RGB color space is the best option because it results in faster performance with a codec like MJPEG (Multi-part JPEG) which is the final requirement for the Blender Game Engine stream. I hope this theoretical explanation superveniently describes the challenge I've been trying to crack.&lt;/p&gt;
&lt;p&gt;FFmpeg built with &lt;code&gt;v4l2-utils&lt;/code&gt; support is used for the Stereo Streaming.&lt;/p&gt;
&lt;h2&gt;Experiments with Blender&lt;/h2&gt;
&lt;p&gt;I tried capturing the two video devices directly from the Blender Game Engine application. It was a good experience learning about creating basic Blender Games.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Blender Game" src="http://siddhantsci.org/images/blender-try-two-sources.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;The workflow to this end was -&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Create two Cube Meshes&lt;/li&gt;
&lt;li&gt;Enable GLSL shading mode&lt;/li&gt;
&lt;li&gt;Set Object Shading to &lt;code&gt;Shadeless&lt;/code&gt; to enhance brightness&lt;/li&gt;
&lt;li&gt;Add Image Textures to both images&lt;/li&gt;
&lt;li&gt;Add a &lt;code&gt;sensor&lt;/code&gt; that is triggered to &lt;code&gt;True&lt;/code&gt; &lt;strong&gt;always&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Add a Python script controller corresponding to each sensor.&lt;/li&gt;
&lt;li&gt;The script to control the right camera of the stereo system is -&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;import&lt;/span&gt; &lt;span class="n"&gt;VideoTexture&lt;/span&gt;
&lt;span class="n"&gt;import&lt;/span&gt; &lt;span class="n"&gt;bge&lt;/span&gt;

&lt;span class="n"&gt;contr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;bge&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;logic&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getCurrentController&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;obj&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;contr&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;owner&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;not&lt;/span&gt; &lt;span class="n"&gt;hasattr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bge&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;logic&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;video&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;matID&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;VideoTexture&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;materialID&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;obj&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;IMimage&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;png&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;bge&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;logic&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;video&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;VideoTexture&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Texture&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;obj&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;matID&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;bge&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;logic&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;video&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;source&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;VideoTexture&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;VideoFFmpeg&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;/dev/video2&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;bge&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;logic&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;video&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;source&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scale&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;True&lt;/span&gt;
    &lt;span class="n"&gt;bge&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;logic&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;video&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;source&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;flip&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;True&lt;/span&gt;
    &lt;span class="n"&gt;bge&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;logic&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;video&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;source&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;framerate&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.2&lt;/span&gt;
    &lt;span class="n"&gt;bge&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;logic&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;video&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;source&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;repeat&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="n"&gt;bge&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;logic&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;video&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;source&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;play&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;In Video 2 fps: &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;bge&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;logic&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;video&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;source&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;framerate&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;    
&lt;span class="n"&gt;bge&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;logic&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;video&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;refresh&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;But it turns out Blender Game Engine does not provide extensive Video Device control. It relies on the default settings provided by Video4Linux. Since the Minoru camera is unable to stream both camera outputs at 30 frames per second - Blender simply gives in and compromises by playing the first camera output that it receives. Video4Linux simply reports &lt;code&gt;Insufficient Memory&lt;/code&gt; for the other stream.&lt;/p&gt;
&lt;p&gt;The output could only support one camera at a time -
&lt;img alt="Blender cameras" src="http://siddhantsci.org/images/blender-try-two-cameras.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;The BGE documentation is ambiguous in the use of the VideoTexture command while controlling webcam devices.&lt;/p&gt;
&lt;p&gt;It was an exciting learning experience about contemporary game design nevertheless. The take-away was that Blender Game Engine is unable to handle cameras at the hardware level. Network Streaming with FFmpeg was the only option. &lt;/p&gt;
&lt;h2&gt;FFmpeg - the one-stop-shop for Multimedia&lt;/h2&gt;
&lt;p&gt;My search for the perfect tool for streaming ended with FFmpeg. It amazes me how versatile this software is. Some people even call it the &lt;a href="https://sonnati.wordpress.com/2011/08/08/ffmpeg-%E2%80%93-the-swiss-army-knife-of-internet-streaming-%E2%80%93-part-ii/"&gt;Swiss-army knife of Internet streaming&lt;/a&gt;. So I had to basically work with Streams.
Streams are essentially Multimedia resources which are identified with the help of a &lt;em&gt;Media Resource Locator&lt;/em&gt; (&lt;strong&gt;MRL&lt;/strong&gt;). A combination of &lt;code&gt;ffmpeg&lt;/code&gt; and &lt;code&gt;ffserver&lt;/code&gt; is what I used to achieve the desired results. The stereoscopic stream produced will be used by multiple applications-&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Streaming to the Head-Mounted Device (currently Oculus Rift)&lt;/li&gt;
&lt;li&gt;Processing Martian environment's video.&lt;/li&gt;
&lt;li&gt;View in the ERAS application from ground control.&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;Why FFmpeg?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;It is fast, reliable, and free.&lt;/li&gt;
&lt;li&gt;It provides a complete solution from streaming and transcoding to media playback, conversion, and probe analysis.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Quoting from its &lt;a href="http://ffmpeg.org/ffmpeg.html"&gt;documentation&lt;/a&gt; -&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ffmpeg reads from an arbitrary number of input "files" (which can be regular files, pipes, network streams, grabbing devices, etc.), specified by the -i option, and writes to an arbitrary number of output "files", which are specified by a plain output filename. Anything found on the command line which cannot be interpreted as an option is considered to be an output filename. &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I tinkered with loads of &lt;code&gt;ffmpeg&lt;/code&gt; options and created a lot of useful junkcode. The good thing about GSoC is that it makes you aware of the open-source influences out there. Throughout this work on streaming, I was motivated by the philosophy of &lt;strong&gt;Andrew Tridgell&lt;/strong&gt; who says that &lt;a href="http://samba.org/ftp/tridge/talks/junkcode.pdf"&gt;"junkcode can be an important learning tool"&lt;/a&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;ffmpeg&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="n"&gt;v4l2&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;framerate&lt;/span&gt; &lt;span class="mi"&gt;15&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;video_size&lt;/span&gt; &lt;span class="mi"&gt;640&lt;/span&gt;&lt;span class="n"&gt;x480&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;video1&lt;/span&gt; &lt;span class="n"&gt;outp1&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mp4&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;framerate&lt;/span&gt; &lt;span class="mi"&gt;15&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;video2&lt;/span&gt; &lt;span class="n"&gt;outp2&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mp4&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This resulted in a steady video stream -&lt;/p&gt;
&lt;p&gt;A sample of three different frames at &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;frame&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1064&lt;/span&gt; &lt;span class="n"&gt;fps&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt; &lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;27.0&lt;/span&gt; &lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;27.0&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;631&lt;/span&gt;&lt;span class="n"&gt;kB&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mo"&gt;00&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mo"&gt;01&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mf"&gt;07.06&lt;/span&gt;
&lt;span class="n"&gt;frame&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1072&lt;/span&gt; &lt;span class="n"&gt;fps&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt; &lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;27.0&lt;/span&gt; &lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;27.0&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;723&lt;/span&gt;&lt;span class="n"&gt;kB&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mo"&gt;00&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mo"&gt;01&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mf"&gt;07.60&lt;/span&gt;
&lt;span class="n"&gt;frame&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1079&lt;/span&gt; &lt;span class="n"&gt;fps&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt; &lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;27.0&lt;/span&gt; &lt;span class="n"&gt;q&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;27.0&lt;/span&gt; &lt;span class="n"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;750&lt;/span&gt;&lt;span class="n"&gt;kB&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mo"&gt;00&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mo"&gt;01&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mf"&gt;08.06&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Learning about the &lt;code&gt;ffmpeg-filters&lt;/code&gt; made this experience worthwhile. I was not able to overlay videos side-by-side and combine them in real-time. This is the script that I used -&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;ffmpeg&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="mi"&gt;320&lt;/span&gt;&lt;span class="n"&gt;x240&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="mi"&gt;24&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="n"&gt;video4linux2&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;video1&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="mi"&gt;320&lt;/span&gt;&lt;span class="n"&gt;x240&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="mi"&gt;24&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="n"&gt;video4linux2&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;video2&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;filter_complex&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;[0:v]setpts=PTS-STARTPTS, pad=iw*2:ih[bg];[1:v]setpts=PTS-STARTPTS[fg]; [bg][fg]overlay=w&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="n"&gt;libx264&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;crf&lt;/span&gt; &lt;span class="mi"&gt;23&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;preset&lt;/span&gt; &lt;span class="n"&gt;medium&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;movflags&lt;/span&gt; &lt;span class="n"&gt;faststart&lt;/span&gt; &lt;span class="n"&gt;nerf&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mp4&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;It basically tells ffmpeg to use a resolution of 320x240 and 24 fps for each of the camera devices and apply an overlay filter to enable side-by-side video output. &lt;code&gt;PTS-STARTPTS&lt;/code&gt; allows for time synchronization of the two streams and the presets enable efficient encoding.&lt;/p&gt;
&lt;p&gt;I shot a video using the Minoru video camera. After applying the Overlay filter, I got a nice video with the Left and Right video streams arranged side-by-side. In this screenshot, I am pointing my little brother's Nerf guns towards each of the Minoru's two cameras -&lt;/p&gt;
&lt;p&gt;&lt;img alt="Minoru Nerf Gun" src="http://siddhantsci.org/images/minoru-nerf.png" /&gt;&lt;/p&gt;
&lt;p&gt;I can experiment with the &lt;strong&gt;Stereoscopic anaglyph filters&lt;/strong&gt; to extend it to a single-screen 3D live stream. But the present task involves streaming to the Oculus Rift which is what I'll be working on next. In addition to &lt;code&gt;ffmpeg&lt;/code&gt;, I also made use of &lt;code&gt;ffserver&lt;/code&gt; and &lt;code&gt;ffplay&lt;/code&gt; in my Streaming workflow. These have been explained in a &lt;a href="http://siddhantsci.org/blog/2015/07/01/mid-term-report-gsoc-15/"&gt;previous post&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Experiments with &lt;code&gt;v4l2stereo&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;Working with stereoscopic cameras is atypical to a traditional Computer Vision workflow. Each of the cameras require calibration in order for Range-Imaging applications like depth maps and point clouds to work. I calibrated my camera using the excellent &lt;a href="https://github.com/bashrc/v4l2stereo"&gt;v4l2stereo&lt;/a&gt; tool.&lt;/p&gt;
&lt;p&gt;Here are some screenshots -&lt;/p&gt;
&lt;p&gt;&lt;img alt="Minoru Calibration" src="http://siddhantsci.org/images/minoru-calibration.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;Basic Feature detection -&lt;/p&gt;
&lt;p&gt;&lt;img alt="Minoru Calibration" src="http://siddhantsci.org/images/minoru-features.jpg" /&gt;&lt;/p&gt;
&lt;h2&gt;Closing remarks&lt;/h2&gt;
&lt;p&gt;This was a very hectic couple of weeks. The output I produced pales in comparison to the tinkering that I had been doing. I'll be using all the important scripts that did not make it to the final repository in the documentation so that future students won't have to wade through the insurmountable learning curve of Multimedia Streaming. All the work regarding this can be found &lt;a href="https://bitbucket.org/italianmarssociety/eras/src/a31a7a135eb0315c4d3aa4d968e0832666af14eb/servers/telerobotics/streams/?at=default"&gt;here&lt;/a&gt;. I realized the overwhelming importance of IRC channels when I got help from #ffmpeg and #v4l2 channels when I was stuck with no end in sight. I gathered a GREAT DEAL of experience in Video Streaming which I hope will go a long way.&lt;/p&gt;
&lt;p&gt;This has been one giant bi-weekly report. Thank you for reading. &lt;em&gt;Ciao!&lt;/em&gt;&lt;/p&gt;</summary><category term="GSoC"></category><category term="Python"></category><category term="PSF"></category><category term="computers"></category><category term="science"></category><category term="exploration"></category><category term="space"></category><category term="mars"></category><category term="IMS"></category><category term="Italian Mars Society"></category></entry><entry><title>Remote tests in Telerobotics</title><link href="http://siddhantsci.org/blog/2015/07/08/remote-tests-in-telerobotics/" rel="alternate"></link><updated>2015-07-08T19:53:52+00:00</updated><author><name>Siddhant Shrivastava</name></author><id>tag:siddhantsci.org,2015-07-08:blog/2015/07/08/remote-tests-in-telerobotics/</id><summary type="html">&lt;p&gt;Ciao :)  The &lt;em&gt;sixth week&lt;/em&gt; of GSoC 2015 got over. According to the &lt;a href="http://erasproject.org/2015-gsoc/#2"&gt;Telerobotics project timeline&lt;/a&gt;, this week was supposed to be the &lt;strong&gt;Buffer Week&lt;/strong&gt; to account for any unforeseen work that may pop up. We at the &lt;strong&gt;Italian Mars Society&lt;/strong&gt; were trying to get ROS communication possible over a &lt;em&gt;large&lt;/em&gt; network. After effective discussion via mail and prioritizing on Trello, the &lt;strong&gt;first Husky test&lt;/strong&gt; was scheduled on July 1, &lt;strong&gt;second test&lt;/strong&gt; on July 7 and the &lt;strong&gt;third test&lt;/strong&gt; on July 8. It was an international effort spanning timezones in UTC-5:00, UTC+2:00, and UTC+5:30 regions. So zeroing in on a common time was an interesting sub-challenge in itself.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;By a &lt;strong&gt;large&lt;/strong&gt; network, I mean this -&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img alt="Remote Testing" src="http://siddhantsci.org/images/remote-problem.png" /&gt;&lt;/p&gt;
&lt;p&gt;On visceral observation, the problem statement looks quite tractable and practical. But like all problems in Computer Networks, this one looked easy in theory, but frustrated the budding Computer Scientist in me as the solutions proposed didn't work out.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Husky Test 1&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Matt (from the Space Research Systems Group, Carleton University), Franco, and I were trying to get the Husky UGV in Canada to respond to the commands sent from the three parts of world involved (Canada, India, Italy). The few problems we came across -&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;ROS version issues caused a minor problem. The Husky robot was running an older version of ROS (Hydro) while Franco and I were using the newer version (Indigo). This caused problems in reading certain Husky messages. Solution - Upgrade ROS version on the Husky robot OR downgrade our version to ROS Hydro and Ubuntu 12.04.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Network Issues - Unable to communicate with all three computers in all cases. There was no bidirectional communication between the ROS computers and ports were blocked.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Success&lt;/strong&gt; - GPS Messages and status messages were received from the Husky robot laptop set as the ROS Master. But the Husky laptop was unable to receive Teleoperation messages from Franco's computer and my computer (even though it detected that we were publishing messages). Again a Network problem.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;Solution - &lt;strong&gt;Virtual Private Networks&lt;/strong&gt;, well almost...&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;At first, I had to ensure that the TP-Link WiFi Router at home was not creating problems. To ensure this, I added my laptop interface in the &lt;strong&gt;Demilitarized Zone (DMZ)&lt;/strong&gt;, and enabled &lt;strong&gt;Port Forwarding&lt;/strong&gt; for all the ports of interest.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Success&lt;/em&gt; with Blender Game Engine Streaming&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Now, this solved quite a few problems - my public IP could now behave like one. To prove this, Franco and I held a Web-Stream session in which his laptop in Italy behaved as the Blender Game Engine Client while I provided a live video feed from the Minoru Camera while using a &lt;strong&gt;FFMpeg Server&lt;/strong&gt;. His words - "You are live. I can see the stream." provided the much-needed boost I required to tackle the pending Computer Networks problems I had to solve in the following couple of days.&lt;/p&gt;
&lt;p&gt;Coming to the VPN problem, I first read about the various VPN Server solutions available, like -&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;OpenVPN&lt;/li&gt;
&lt;li&gt;PPTP (Point-to-Point Tunneling Protocol)&lt;/li&gt;
&lt;li&gt;IPSec&lt;/li&gt;
&lt;li&gt;SSH Tunneling&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The second Husky test was done with a PPTP VPN setup which wasn't quite succesful. The reason being - ROS requires bidirectional communication between the peers, and I couldn't become a peer while I was the VPN server. It caused a slew of other pesky problems like &lt;code&gt;REQ TIMEOUTS&lt;/code&gt;, Disconnected ROS Nodes, disabling Internet on the VPN server, etc. But as a start, it was assuring that the problem could be solved. I realized that the learning curve for working with computers at the scale of the Internet is no child's play. But there was another takeaway with the second Husky test. Andrea (from the Husky team) could work with my remote node as the ROS master and still get the Husky up and running. This means that all the Husky traffic and node maintenance could be relegated through my PC and transferred to the Husky. &lt;em&gt;Much assuring.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Armed with the Computer Networks concepts I learnt at my college, I set on to set up the slightly tougher OpenVPN server. This is a snapshot of the OpenVPN access server that I set up -&lt;/p&gt;
&lt;p&gt;&lt;img alt="OpenVPN users" src="http://siddhantsci.org/images/openvpn-users.png" /&gt;&lt;/p&gt;
&lt;p&gt;I was not only able to set up a world-wide VPN, but also able to set up communication among the peers. But the firewalls on the Husky computer network were strong for it and sent Andrea's laptop in a continous &lt;em&gt;Trying to Reconnect&lt;/em&gt; loop. There went our hopes with OpenVPN. I am still looking into this issue. The main issue was that the UDP channel of OpenVPN was accessible in the Husky network but not the TCP channels. This caused intermittent connection losses and the OpenVPN client couldn't figure out what to do. There must be a solution to this and I'll find it.&lt;/p&gt;
&lt;p&gt;Throughout this experience, I learnt a lot of new things about practical Computer Networks. Once I'm able to crack the VPN problem, I could put it to use in diverse scenarios (remote robotics testing, as a road warrior, Internet of Things applications, creating a network of friends, etc. ). VPN brings everyone on the same page (or logical subnet). I also did quite a bit of work with the Stereo Video Streaming which would be the theme of my next post. Stay tuned.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Ciao!&lt;/em&gt;&lt;/p&gt;</summary><category term="GSoC"></category><category term="Python"></category><category term="PSF"></category><category term="computers"></category><category term="science"></category><category term="exploration"></category><category term="space"></category><category term="mars"></category><category term="IMS"></category><category term="Italian Mars Society"></category></entry><entry><title>Mid-term Report - GSoC '15</title><link href="http://siddhantsci.org/blog/2015/07/01/mid-term-report-gsoc-15/" rel="alternate"></link><updated>2015-07-01T19:53:52+00:00</updated><author><name>Siddhant Shrivastava</name></author><id>tag:siddhantsci.org,2015-07-01:blog/2015/07/01/mid-term-report-gsoc-15/</id><summary type="html">&lt;p&gt;Hi all! I made it through the first half of the &lt;a href="http://siddhantsci.org/category/gsoc.html"&gt;GSoC 2015 program&lt;/a&gt;. This is the &lt;strong&gt;evaluation week&lt;/strong&gt; of the &lt;a href="http://www.google-melange.com/gsoc/homepage/google/gsoc2015"&gt;Google Summer of Code 2015 program&lt;/a&gt; with the &lt;a href="https://www.python.org/psf/"&gt;Python Software Foundation&lt;/a&gt; and the &lt;a href="http://erasproject.org/"&gt;Italian Mars Society ERAS Project&lt;/a&gt;. Mentors and students evaluate the journey so far in the program by answering some questions about their students and mentors respectively. On comparing with the timeline, I reckoned that I am on track with the project so far.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The entire &lt;strong&gt;Telerobotics with Virtual Reality&lt;/strong&gt; project can be visualized in the following diagram -&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img alt="Project Architecture" src="http://siddhantsci.org/images/telerobotics-diagram.png" /&gt;&lt;/p&gt;
&lt;h2&gt;Achievements-&lt;/h2&gt;
&lt;h3&gt;Husky-ROS-Tango Interface&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ROS-Tango interfaces&lt;/strong&gt; to connect the &lt;strong&gt;Telerobotics&lt;/strong&gt; module with the &lt;strong&gt;rest of ERAS&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ROS Interfaces for Navigation and Control of Husky
&lt;img alt="Husky Navigation" src="http://siddhantsci.org/images/navigate-ros.png" /&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://siddhantsci.org/blog/2015/06/24/the-half-life-of-telerobotics/"&gt;Logging Diagnostics&lt;/a&gt; of the robot to the Tango Bus&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;Driving the Husky around using human commands
&lt;img alt="Husky Commands" src="http://siddhantsci.org/images/husky-command.png" /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Video Streaming&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Single Camera Video streaming to Blender Game Engine&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is how it works. &lt;strong&gt;ffmpeg&lt;/strong&gt; is used as the streaming server to which Blender Game Engine subscribes.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;ffserver.conf&lt;/code&gt; file is configured as follows which describes the characterstics of the stream:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nb"&gt;Port&lt;/span&gt; &lt;span class="mi"&gt;8190&lt;/span&gt;
&lt;span class="nx"&gt;BindAddress&lt;/span&gt; &lt;span class="mf"&gt;0.0.0.0&lt;/span&gt;
&lt;span class="nx"&gt;MaxClients&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;
&lt;span class="nx"&gt;MaxBandwidth&lt;/span&gt; &lt;span class="mi"&gt;50000&lt;/span&gt;
&lt;span class="nx"&gt;NoDaemon&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nx"&gt;Feed&lt;/span&gt; &lt;span class="nx"&gt;webcam.ffm&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="nb"&gt;file&lt;/span&gt; &lt;span class="p"&gt;/&lt;/span&gt;&lt;span class="nx"&gt;tmp&lt;/span&gt;&lt;span class="p"&gt;/&lt;/span&gt;&lt;span class="nx"&gt;webcam.ffm&lt;/span&gt;
&lt;span class="nx"&gt;FileMaxSize&lt;/span&gt; &lt;span class="mi"&gt;2000&lt;/span&gt;&lt;span class="nx"&gt;M&lt;/span&gt;
&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nx"&gt;Feed&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nx"&gt;Stream&lt;/span&gt; &lt;span class="nx"&gt;webcam.mjpeg&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="nx"&gt;Feed&lt;/span&gt; &lt;span class="nx"&gt;webcam.ffm&lt;/span&gt;
&lt;span class="nb"&gt;Format&lt;/span&gt; &lt;span class="nx"&gt;mjpeg&lt;/span&gt;
&lt;span class="nx"&gt;VideoSize&lt;/span&gt; &lt;span class="mi"&gt;640&lt;/span&gt;&lt;span class="nx"&gt;x480&lt;/span&gt;
&lt;span class="nx"&gt;VideoFrameRate&lt;/span&gt; &lt;span class="mi"&gt;30&lt;/span&gt;
&lt;span class="nx"&gt;VideoBitRate&lt;/span&gt; &lt;span class="mi"&gt;24300&lt;/span&gt;
&lt;span class="nx"&gt;VideoQMin&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="nx"&gt;VideoQMax&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;
&lt;span class="o"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nx"&gt;Stream&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Then the Blender Game Engine and its associated Python library &lt;code&gt;bge&lt;/code&gt; kicks in to display the stream on the &lt;strong&gt;Video Texture&lt;/strong&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="cp"&gt;# Get an instance of the video texture&lt;/span&gt;
&lt;span class="n"&gt;bge&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;logic&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;video&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;bge&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;texture&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Texture&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;obj&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ID&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="cp"&gt;# a ffmpeg server is streaming the feed on the IP:PORT/FILE&lt;/span&gt;
&lt;span class="cp"&gt;# specified in FFMPEG_PARAM,&lt;/span&gt;
&lt;span class="cp"&gt;# BGE reads the stream from the mjpeg file.&lt;/span&gt;

&lt;span class="n"&gt;bge&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;logic&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;video&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;source&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;bge&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;texture&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;VideoFFmpeg&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;FFMPEG_PARAM&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;bge&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;logic&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;video&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;source&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;play&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;bge&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;logic&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;video&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;refresh&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;The entire source code for single camera streaming can be found &lt;a href="https://bitbucket.org/italianmarssociety/v-eras-blender/src/42063c0b489152a9f124f80824ad095a752c29ff/scripts/webstream/single%20camera/?at=default"&gt;in this repository&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Setting up the &lt;strong&gt;Minoru Camera&lt;/strong&gt; for stereo vision
&lt;img alt="Minoru Camera" src="http://siddhantsci.org/images/minoru.jpg" /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It turns out this camera can stream at &lt;strong&gt;30 frames per second&lt;/strong&gt; for both cameras. The last week has been particularly challenging to figure out the optimal settings for the Minoru Webcam to work. It depends on the Video Buffer Memory allocated by the &lt;strong&gt;Linux Kernel&lt;/strong&gt; for &lt;code&gt;libuvc&lt;/code&gt; and &lt;code&gt;v4l2&lt;/code&gt; compatible webcams. Different kernel versions result in different performances. It is inefficient to stream the left and right cameras at a frame rate greater than 15 fps with the kernel version that I am using.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Setting up the Oculus Rift DK1 for the &lt;strong&gt;Virtual Reality&lt;/strong&gt; work in the upcoming second term
&lt;img alt="Oculus Rift" src="http://siddhantsci.org/images/oculus-rift.jpg" /&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Crash-testing and Roadblocks&lt;/h2&gt;
&lt;p&gt;This project was not without its share of obstacles. A few memorable roadblocks come to mind-&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Remote Husky testing&lt;/strong&gt; - Matt (from &lt;strong&gt;Canada&lt;/strong&gt;), Franco (from &lt;strong&gt;Italy&lt;/strong&gt;), and I (from &lt;strong&gt;India&lt;/strong&gt;) tested whether we could remotely control Husky. The main issue we faced was &lt;strong&gt;Network Connectivity&lt;/strong&gt;. We were all on different networks geographically, which the ROS in our machines could not resolve. Thus some messages (like GPS) were accessible  whereas the others (like Husky Status messages) were not. The solution we sought is to create a &lt;strong&gt;Virtual Private Network&lt;/strong&gt; for our computers for future testing.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Minoru Camera Performance differences&lt;/strong&gt; - Since the Minoru's performance varies with the Kernel version, I had to bump down the frames per second to &lt;em&gt;15 fps&lt;/em&gt; for both cameras and stream them in the Blender Game Engine. This temporary hack should be resolved as ERAS moves to newer Linux versions.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Tango related&lt;/strong&gt; - Tango-controls is a sophisticated piece of SCADA library with a server database for maintaining device server lists. It was painful to use the provided GUI - Jive to configure the device servers. To make the process in line with other development activities, I wrote a little CLI-based Device server registration and de-registration interactive script. A &lt;a href="http://siddhantsci.org/blog/2015/06/18/when-two-distributed-systems-meet/"&gt;blog post&lt;/a&gt; which explains this in detail.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Common testing platform&lt;/strong&gt; -  I needed to use ROS Indigo, which is supported only on Ubuntu 14.04. ERAS is currently using Ubuntu 14.10. In order to enable Italian Mars Society and the members to execute my scripts, they needed my version of Ubuntu. &lt;strong&gt;Solution&lt;/strong&gt; - Virtual Linux Containers. We are using a &lt;strong&gt;Docker Image&lt;/strong&gt; which my mentors can use on their machine regarding of their native OS. &lt;a href="http://siddhantsci.org/blog/2015/06/12/all-for-docker-docker-for-all/"&gt;This post&lt;/a&gt; explains this point.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Expectations from the second term&lt;/h2&gt;
&lt;p&gt;This is a huge project in that I have to deal with &lt;em&gt;many different technologies&lt;/em&gt; like -&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Robot Operating System&lt;/li&gt;
&lt;li&gt;FFmpeg&lt;/li&gt;
&lt;li&gt;Blender Game Engine&lt;/li&gt;
&lt;li&gt;Oculus VR SDK&lt;/li&gt;
&lt;li&gt;Tango-Controls&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So far, the journey has been exciting and there has been a lot of learning and development. The second term will be intense, challenging, and above all, fun.&lt;/p&gt;
&lt;p&gt;To-do list -&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Get Minoru webcam to work with ffmpeg streaming&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use Oculus for an Augmented Reality application
&lt;img alt="Oculus Rift" src="http://siddhantsci.org/images/oculus-mars.jpg" /&gt;
&lt;a href="https://vimeo.com/111243246"&gt;Source&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Integrate Bodytracking with Telerobotics&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;Automation in Husky movement and using a UR5 manipulator&lt;/li&gt;
&lt;li&gt;Set up a &lt;a href="http://pptpclient.sourceforge.net/"&gt;PPTP&lt;/a&gt; or &lt;a href="https://openvpn.net/"&gt;OpenVPN&lt;/a&gt; for ERAS&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Time really flies by fast when I am learning new things. GSoC so far has taught me how to not be a &lt;a href="https://www.quora.com/What-are-the-characteristics-of-a-bad-software-engineer"&gt;bad software engineer&lt;/a&gt;, but also how to be a good open source community contributor. That is what the spirit of Google Summer of Code is about and I have imbibed a lot. Besides, working with the Italian Mars Society has also motivated me to learn the Italian language. So Python is not the only language that I'm practicing over this summer ;)&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Here's to the second term of Google Summer of Code 2015!
&lt;img alt="GSoC Banner" src="http://siddhantsci.org/images/gsoc-banner.png" /&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Ciao :)&lt;/p&gt;</summary><category term="GSoC"></category><category term="Python"></category><category term="PSF"></category><category term="computers"></category><category term="science"></category><category term="exploration"></category><category term="space"></category><category term="mars"></category><category term="IMS"></category><category term="Italian Mars Society"></category></entry><entry><title>The Half-Life of Telerobotics</title><link href="http://siddhantsci.org/blog/2015/06/24/the-half-life-of-telerobotics/" rel="alternate"></link><updated>2015-06-24T19:53:52+00:00</updated><author><name>Siddhant Shrivastava</name></author><id>tag:siddhantsci.org,2015-06-24:blog/2015/06/24/the-half-life-of-telerobotics/</id><summary type="html">&lt;p&gt;Hi all! If you've been following my &lt;a href="http://siddhantsci.org/category/gsoc.html"&gt;previous posts&lt;/a&gt;, you'd have known that the Telerobotics module has been simmering for a couple of weeks. I'm happy to announce that it is almost complete and would hopefully be integrated with Vito's Bodytracking module.&lt;/p&gt;
&lt;p&gt;The last week (week four and five) were the busiest weeks of GSoC for me.&lt;/p&gt;
&lt;h2&gt;Learning Experience&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;I learnt A LOT about Python Software Development&lt;/li&gt;
&lt;li&gt;Different types of &lt;a href="http://www.oreilly.com/programming/free/software-architecture-patterns.csp"&gt;software architectures&lt;/a&gt;,&lt;/li&gt;
&lt;li&gt;&lt;a href="http://pyvideo.org/video/1093/the-development-process-of-python"&gt;The development process of Python&lt;/a&gt; by one of the members of the Italian Mars Society who has been the reason I'm able to write more Pythonic code  - &lt;a href="http://wolfprojects.altervista.org/"&gt;Ezio Melotti&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.esrf.eu/computing/cs/tango/tango_doc/kernel_doc/pytango/latest/quicktour.html#pytango-quick-tour"&gt;PyTango&lt;/a&gt; Development&lt;/li&gt;
&lt;li&gt;ipython and how helpful it can be for Tango applications&lt;/li&gt;
&lt;li&gt;Message queues - Both ROS and Tango utilize ZeroMQ - which makes integration of ROS and Tango much scalable&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.vlfeat.org/overview/sift.html"&gt;SIFT&lt;/a&gt; in Python - I will be working with my mentor Fabio Nigi on this very soon&lt;/li&gt;
&lt;li&gt;Making my own stereo camera&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Deliverables&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;A &lt;strong&gt;ROS node&lt;/strong&gt; which collects information from all interesting topics from the Husky robot. This can be found &lt;a href="https://bitbucket.org/italianmarssociety/eras/src/db8c7061f4768534ebb2621296a20a016bd240ad/servers/telerobotics/src/robot-info-collector.py?at=default"&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;A &lt;strong&gt;Tango Server&lt;/strong&gt; which integrates with ROS to provide diagnostic information from the robot (&lt;em&gt;Battery Status, Temperature Levels, Current Draw, Voltate, Error Conditions&lt;/em&gt; )&lt;/li&gt;
&lt;li&gt;A simulated version of the Tango server for the Planning and Scheduling application that Shridhar is working on. These can be accessed &lt;a href="https://bitbucket.org/italianmarssociety/eras/src/db8c7061f4768534ebb2621296a20a016bd240ad/servers/telerobotics/src/robot-diagnostics-server.py?at=default"&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt; Soft Real-time network streaming&lt;/strong&gt; FFMPEG server and Blender Client for a single camera video stream. This can be found &lt;a href="https://bitbucket.org/italianmarssociety/v-eras-blender/src/42063c0b489152a9f124f80824ad095a752c29ff/scripts/webstream/single%20camera/?at=default"&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Under &lt;strong&gt;heavy&lt;/strong&gt; Development&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Integration of Bodytracking with Telerobotics. The following message format has been decided upon by the mentors and students:&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="cp"&gt;# Attribute definitions for various diagnostic messages&lt;/span&gt;
  &lt;span class="n"&gt;moves&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;attribute&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Linear and angular displacement&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt;
                              &lt;span class="n"&gt;display_level&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;DispLevel&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;EXPERT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                              &lt;span class="n"&gt;access&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;AttrWriteType&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;READ&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                              &lt;span class="n"&gt;unit&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;(meters, radians)&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                              &lt;span class="n"&gt;fget&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;getMoves&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;polling_period&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;POLLING&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                              &lt;span class="n"&gt;max_dim_x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;max_dim_y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                              &lt;span class="n"&gt;doc&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;An attribute for Linear and angular displacements&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Vito's Bodytracker would &lt;strong&gt;publish events&lt;/strong&gt; in the form of Tango events. The associated data would be a float tuple of dimensions &lt;strong&gt;2,1&lt;/strong&gt; (2 columns, 1 row). Such a tuple, like (3.4, 1.2) would specify a relative linear and angular displacement of the astronaut. My Telerobotics module would &lt;strong&gt;subscribe to this Tango event&lt;/strong&gt; and &lt;em&gt;transform&lt;/em&gt; this data to a &lt;strong&gt;Twist&lt;/strong&gt; message that the Husky can understand.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Extension of Camera Streaming to a dual camera setup. I am extending the streaming capabilty for a stereo camera.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Mid-term evaluations start tomorrow! Eagerly looking forward to them. It has been an eventful and productive half summer of code. I hope the next half is even more exciting and challenging as the one that passed.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Ciao&lt;/em&gt;&lt;/p&gt;</summary><category term="GSoC"></category><category term="Python"></category><category term="PSF"></category><category term="computers"></category><category term="science"></category><category term="exploration"></category><category term="space"></category><category term="mars"></category><category term="IMS"></category><category term="Italian Mars Society"></category></entry><entry><title>When two Distributed Systems meet!</title><link href="http://siddhantsci.org/blog/2015/06/18/when-two-distributed-systems-meet/" rel="alternate"></link><updated>2015-06-18T19:53:52+00:00</updated><author><name>Siddhant Shrivastava</name></author><id>tag:siddhantsci.org,2015-06-18:blog/2015/06/18/when-two-distributed-systems-meet/</id><summary type="html">&lt;p&gt;Hi! This post is meant to be an insight into the experience and progress of the third and fourth weeks of my (a)vocation with the Google Summer of Code Program. Things got much pacier and smooth in the past two weeks. I've been able to get a stable codebase up and running with respect to the aims discussed in the timeline.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Sublime Text Workspace" src="http://siddhantsci.org/images/workspace2.png" /&gt;
&lt;the usual rant&gt; I had to totally restructure my programming workspace for the second time to support Intelligent IDE like features since the Python packages I am working with (ROS and Tango) have a fair number of modules whose documentation I need to read on the fly while coding away. Thus I set up both my &lt;strong&gt;Vim and Sublime Text&lt;/strong&gt; environments to support  &lt;em&gt;intelli-sense&lt;/em&gt;, &lt;em&gt;code completion&lt;/em&gt;, &lt;em&gt;block syntax completion&lt;/em&gt;, etc. I also added a dual monitor setup with the unused LCD television at my home to make for an efficient programming ambience.
&lt;usual rant&gt;&lt;/p&gt;
&lt;h2&gt;Telerobotics Code Pushed&lt;/h2&gt;
&lt;p&gt;As I mentioned in my &lt;a href="http://siddhantsci.org/blog/2015/04/29/gsoc-2015-with-the-italian-mars-society/"&gt;first post&lt;/a&gt;, the contributors of the &lt;strong&gt;Italian Mars Society&lt;/strong&gt; are given &lt;em&gt;write access&lt;/em&gt; to the online Bitbucket repository. This is a tremendous responsibility to ensure that the updates don't disturb the stability of the project. To work with this, I follow the simple and effective advice of my mentors -&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;hg&lt;/span&gt; &lt;span class="n"&gt;pull&lt;/span&gt;
&lt;span class="n"&gt;hg&lt;/span&gt; &lt;span class="n"&gt;update&lt;/span&gt;
&lt;span class="n"&gt;hg&lt;/span&gt; &lt;span class="n"&gt;add&lt;/span&gt; &lt;span class="p"&gt;.&lt;/span&gt;
&lt;span class="n"&gt;hg&lt;/span&gt; &lt;span class="n"&gt;commit&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;m&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;My awesome Commit Message&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;hg&lt;/span&gt; &lt;span class="n"&gt;push&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This simple algorithm ensures that all students can work at their pace without breaking the system. &lt;a href="http://hginit.com/"&gt;This simple tutorial&lt;/a&gt; can help the uninitiated to understand what I just said.&lt;/p&gt;
&lt;p&gt;So while working with Tango servers for my project, I had to constantly use the bundled GUI - &lt;strong&gt;Jive&lt;/strong&gt; which works as a one-stop solution for &lt;a href="http://www.esrf.eu/computing/cs/tango/tango_doc/kernel_doc/pytango/latest/quicktour.html"&gt;Device Servers&lt;/a&gt;. But my primordial hacker instincts prompted me to write a &lt;a href="https://en.wikipedia.org/wiki/Command-line_interface"&gt;CLI&lt;/a&gt; solution to add and remove device servers using the amazing &lt;a href="http://www.esrf.eu/computing/cs/tango/tango_doc/kernel_doc/pytango/latest/#"&gt;PyTango API&lt;/a&gt;. Thanks to Ezio's excellent comments on my commits, I've been able to contribute a Pythonic solution for working with Device Servers in a jiffy. The script can be found &lt;a href="https://bitbucket.org/italianmarssociety/eras/src/2da8222593354228a1eb426bef556654e794365c/servers/telerobotics/utility/setup-device.py?at=default"&gt;here&lt;/a&gt;. It has a nice UI to help the user figure out what he/she needs to enter. I have yet to correct some formatting errors to make it more consistent with PEP8 and the &lt;a href="http://docs.python.org//glossary.html#term-eafp"&gt;EAFP&lt;/a&gt; idiom. The current stage of argument validation is more like LBYL (Look Before You Leap) which is slow for the script's use-case.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The second module&lt;/strong&gt; I pushed is the &lt;strong&gt;Husky Test&lt;/strong&gt; script to ensure if the Husky installation works or not on a particular setup. The &lt;a href="https://bitbucket.org/italianmarssociety/eras/src/2da8222593354228a1eb426bef556654e794365c/servers/telerobotics/utility/test_husky.py?at=default"&gt;test script&lt;/a&gt; which allows a Husky to move with a particular linear and angular velocity. The &lt;a href="https://bitbucket.org/italianmarssociety/eras/src/2da8222593354228a1eb426bef556654e794365c/servers/telerobotics/doc/sad.rst?at=default"&gt;Software Architecture Document&lt;/a&gt; was also updated to account for the new changes in the ROS-Tango interface architecture. A better understanding of the SAD can be had in &lt;a href="http://siddhantsci.org/blog/2015/05/29/software-architecture-document-for-telerobotics/"&gt;an earlier post&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Docker&lt;/h2&gt;
&lt;p&gt;I explained the Docker setup and distribution in a &lt;a href="http://siddhantsci.org/blog/2015/06/12/all-for-docker-docker-for-all/"&gt;quick mini-post&lt;/a&gt;. I tested that the X-errors don't impede with the scripts that I have been developing since ROS topics can be accessed from the command line as well. This is a good thing. The Docker repository for my workspace can be found &lt;a href="https://registry.hub.docker.com/u/sidcode/ros-eras/"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Python Reading&lt;/h2&gt;
&lt;p&gt;I have been voraciously consulting the following sources for getting the knack of Python and PyTango programming -&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Python Docs for &lt;a href="http://docs.python.org/2/"&gt;Python 2&lt;/a&gt; and &lt;a href="http://docs.python.org/3/"&gt;Python 3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://shop.oreilly.com/product/0636920027072.do"&gt;Python Cookbook&lt;/a&gt; by O'Reilly Publishers&lt;/li&gt;
&lt;li&gt;&lt;a href="http://shop.oreilly.com/product/0636920032519.do"&gt;Fluent Python&lt;/a&gt; (early access) again by O'Reilly Publishers&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.esrf.eu/computing/cs/tango/tango_doc/kernel_doc/pytango/latest/index.html"&gt;PyTango documentation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The happiest point of all this reading kicked in when I could help Vito to reduce &lt;strong&gt;fifty lines of code to just two&lt;/strong&gt; with the use of the &lt;code&gt;exec&lt;/code&gt; construct in Python. In case you're wondering, this is the &lt;a href="https://bitbucket.org/italianmarssociety/eras/commits/2da8222593354228a1eb426bef556654e794365c#Lservers/body_tracker/tracker/tracker.pyT40"&gt;code written by Vito&lt;/a&gt; -&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;   &lt;span class="nt"&gt;joints&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="cp"&gt;[&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;skeleton_head&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;skeleton_neck&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;skeleton_left_shoulder&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;skeleton_right_shoulder&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;skeleton_left_elbow&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;skeleton_right_elbow&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;skeleton_left_hand&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;skeleton_right_hand&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;skeleton_torso&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;skeleton_left_hip&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;skeleton_right_hip&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;skeleton_left_knee&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;skeleton_right_knee&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;skeleton_left_foot&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="s1"&gt;&amp;#39;skeleton_right_foot&amp;#39;&lt;/span&gt;
    &lt;span class="cp"&gt;]&lt;/span&gt;

    &lt;span class="nt"&gt;attr_init_params&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nt"&gt;dict&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;
        &lt;span class="nt"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;float32&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;,),&lt;/span&gt;
        &lt;span class="nt"&gt;unit&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;m&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;
        &lt;span class="nt"&gt;max_dim_x&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;3&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt;
        &lt;span class="nt"&gt;polling_period&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;POLLING&lt;/span&gt;
    &lt;span class="o"&gt;)&lt;/span&gt;

    &lt;span class="nt"&gt;for&lt;/span&gt; &lt;span class="nt"&gt;joint&lt;/span&gt; &lt;span class="nt"&gt;in&lt;/span&gt; &lt;span class="nt"&gt;joints&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
        &lt;span class="nt"&gt;exec&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;%s = attribute(**attr_init_params)&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="nt"&gt;joint&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Note that without the &lt;code&gt;exec&lt;/code&gt; usage, each line would've to be manually written for each of the joint that we see in the &lt;code&gt;joints&lt;/code&gt; list.&lt;/p&gt;
&lt;h2&gt;Ongoing Stuff&lt;/h2&gt;
&lt;p&gt;There are certain deliverables in the pipeline currently waiting to be pushed to the online repository over the course of the next week. I have been working on -&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ROS-feedback Aggregator Device Server for Tango&lt;/li&gt;
&lt;li&gt;ROS Commander Node for the Husky&lt;/li&gt;
&lt;li&gt;Tango Client to understand Husky status (battery levels, sensor monitor, etc.)&lt;/li&gt;
&lt;li&gt;Mathematical Transformations and Named Tuples for different structures that Telerobotics requires.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;GSoC with PSF and Italian Mars Society is turning out to be fun-and-challenging. Mid-term Evaluations start in a week. Lots of work to do. I strongly hope my next post will be a celebratory one highlighting the pushed code I described in &lt;em&gt;Ongoing Stuff&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Until then, Ciao!&lt;/p&gt;</summary><category term="GSoC"></category><category term="Python"></category><category term="PSF"></category><category term="computers"></category><category term="science"></category><category term="exploration"></category><category term="space"></category><category term="mars"></category><category term="IMS"></category><category term="Italian Mars Society"></category></entry><entry><title>All for Docker; Docker for all!</title><link href="http://siddhantsci.org/blog/2015/06/12/all-for-docker-docker-for-all/" rel="alternate"></link><updated>2015-06-12T19:53:52+00:00</updated><author><name>Siddhant Shrivastava</name></author><id>tag:siddhantsci.org,2015-06-12:blog/2015/06/12/all-for-docker-docker-for-all/</id><summary type="html">&lt;p&gt;Hi! This is going to be a short post about my developments in the Week 3 of my GSoC project. Since my &lt;a href="http://siddhantsci.org/blog/2015/06/08/tango-ing-with-ros-week-2/"&gt;last post&lt;/a&gt;, I have had the chance to work with some exciting state-of-the-art technologies which allow easy distribution and scalability. These are -&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Docker
&lt;img alt="Docker Logo" src="http://siddhantsci.org/images/docker-logo.png" /&gt;&lt;/li&gt;
&lt;li&gt;Tango-Controls
&lt;img alt="Tango Controls logo" src="http://siddhantsci.org/images/tangologo.png" /&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I used the &lt;a href="https://registry.hub.docker.com/_/ubuntu/"&gt;Ubuntu 14.04&lt;/a&gt; &lt;em&gt;Docker Container&lt;/em&gt; to setup my system which can be used by anyone in the world as a common platform to test the applications that I am working on. This has multiple advantages -&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Setup-time for collaborators is null. The developer sets up the Docker container and the community members can use it directly.&lt;/li&gt;
&lt;li&gt;Host platform-independent. It doesn't matter whether the collaborator's host system is Arch Linux, Windows 8, or a specific version of Ubuntu. Docker uses &lt;a href="http://www.toptal.com/linux/separation-anxiety-isolating-your-system-with-linux-namespaces"&gt;Linux namespaces&lt;/a&gt; and ensures a separation of concerns.&lt;/li&gt;
&lt;li&gt;Revision control mechanism. The developer plays around with a Docker Image just as he/she would do with any other &lt;strong&gt;Distribution Revision Control system&lt;/strong&gt;. I &lt;strong&gt;push&lt;/strong&gt; my changes to the repository (Docker image) and my mentors can simply &lt;strong&gt;pull the updates&lt;/strong&gt; to get the new system configuration.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So far, I have setup Tango-Controls, ROS Indigo, and the Husky libraries for my Docker image. These can be found in the &lt;a href="https://registry.hub.docker.com/u/sidcode/ros-eras/"&gt;Docker Registry Hub&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The issues that I am currently facing are -&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Graphics Problems. X-server Bad Drawing errors. A way to get around this will be to better understand how ROS applications use the X-server and then provide Docker the appropriate graphics capabilities. But this does not impede with the Command Line applications of ROS and Tango which I have been working on.&lt;/li&gt;
&lt;li&gt;MySQL connection problems. The workaround currently is to use the Host OS's Tango HOST. I observed that it works fine that way.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is it for this post. I mainly discussed about Docker in this post, which was an important thing that we discussed in the &lt;strong&gt;All-hands meeting on 8th June&lt;/strong&gt;. I'll go into much more detail with Tango Controls in the upcoming blog posts and the biweekly reports.&lt;/p&gt;
&lt;p&gt;Ciao!&lt;/p&gt;</summary><category term="GSoC"></category><category term="Python"></category><category term="PSF"></category><category term="computers"></category><category term="science"></category><category term="exploration"></category><category term="space"></category><category term="mars"></category><category term="IMS"></category><category term="Italian Mars Society"></category></entry><entry><title>Tango-ing with ROS- Week 2!</title><link href="http://siddhantsci.org/blog/2015/06/08/tango-ing-with-ros-week-2/" rel="alternate"></link><updated>2015-06-08T00:53:52+00:00</updated><author><name>Siddhant Shrivastava</name></author><id>tag:siddhantsci.org,2015-06-08:blog/2015/06/08/tango-ing-with-ros-week-2/</id><summary type="html">&lt;p&gt;Hi! This one is about my &lt;strong&gt;second week of the Google Summer of Code 2015 program&lt;/strong&gt;. It was a busy long &lt;strong&gt;week two&lt;/strong&gt; with some crucial design decisions to be implemented and new things to learn. It was also a hectic week of reading how to write better Python code (&lt;code&gt;Fluent Python - O'Reilly Publishers&lt;/code&gt;, maintaining Python2 and Python3 compatibility, etc) After finalizing on the architecture last week (shown below), it was time to work on implementing it -&lt;/p&gt;
&lt;p&gt;&lt;img alt="ROS and Tango" src="http://siddhantsci.org/images/rostango.png" /&gt;&lt;/p&gt;
&lt;p&gt;Evidently from the diagram, there are &lt;strong&gt;two distributed systems&lt;/strong&gt; involved - both significantly complicated. These are -&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tango Controls&lt;/li&gt;
&lt;li&gt;ROS (Robot Operating System)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The  challenge here is to create an &lt;strong&gt;event-triggered Tango Device&lt;/strong&gt; which serves &lt;strong&gt;as both a client and a server&lt;/strong&gt;. This Tango device listens for new events on the Tango bus, and sends data to it when need be. In addition, this is also interfaced with ROS in that the required Tango events for ROS are processed by the device and published to the appropriate &lt;code&gt;TangoROS&lt;/code&gt; topic when required. It also subscribes to &lt;code&gt;ROSTango&lt;/code&gt; topic to listen to any incoming updates from the robot.&lt;/p&gt;
&lt;p&gt;Some use-cases for this are as follows -&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The Bodytracking server pushes the location/orientation data on the bus.&lt;/li&gt;
&lt;li&gt;The TangoROS Device subscribes to the events of the Bodytracking data on the Tango bus.&lt;/li&gt;
&lt;li&gt;When an event is triggered, the device processes the data into ROS-compatible messages (&lt;code&gt;location&lt;/code&gt; and &lt;code&gt;orientation&lt;/code&gt; are &lt;strong&gt;transformed&lt;/strong&gt; into &lt;code&gt;linear velocity&lt;/code&gt; and &lt;code&gt;angular velocity&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;The &lt;em&gt;ROS Commander&lt;/em&gt; node (which is subscribed to the &lt;code&gt;ROSTango&lt;/code&gt; topic)&lt;/li&gt;
&lt;li&gt;The ROS Commander node continuously monitors the robot for different measurements (&lt;strong&gt;sensor readings, battery status, navigation feedback, etc&lt;/strong&gt;). The important signals are published to the &lt;code&gt;ROSTango bus&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is my first time working with the powerful Tango-Controls system. It is used by -&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Italian Mars Society&lt;/li&gt;
&lt;li&gt;The very large solar array network (SAK)&lt;/li&gt;
&lt;li&gt;Synchotrons and Particle Accelerators around Europe&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I'll discuss how I work with Tango and ROS in my next blog post.&lt;/p&gt;
&lt;p&gt;The Italian Mars Society had an All-hands Skype meeting on 8th June, 2015 where all the GSoC students and mentors discussed project status, software architecture document feedback, roadblocks, hardware needs, collaboration, field tests etc.&lt;/p&gt;
&lt;p&gt;Things that were discussed and to be done-&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Docker Image for ROS setup (&lt;strong&gt;very important&lt;/strong&gt;)&lt;/li&gt;
&lt;li&gt;Battery status Tango server&lt;/li&gt;
&lt;li&gt;ROS Tango Client&lt;/li&gt;
&lt;li&gt;ROS Tango server for certain use cases&lt;/li&gt;
&lt;li&gt;Tango events&lt;/li&gt;
&lt;li&gt;Timestamp based Transformation of parameters in a time-series data&lt;/li&gt;
&lt;li&gt;Set up the Minoru 3D camera and the Oculus Rift device&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is a week where I'd like most of these things to fall in place. GSoC is turning out to be exciting and challenging! Til the next post. Over to week three.&lt;/p&gt;
&lt;p&gt;Ciao!&lt;/p&gt;</summary><category term="GSoC"></category><category term="Python"></category><category term="PSF"></category><category term="computers"></category><category term="science"></category><category term="exploration"></category><category term="space"></category><category term="mars"></category><category term="IMS"></category><category term="Italian Mars Society"></category></entry><entry><title>Programming a Mars rover - Week 1!</title><link href="http://siddhantsci.org/blog/2015/06/03/programming-a-mars-rover-week-1/" rel="alternate"></link><updated>2015-06-03T00:53:52+00:00</updated><author><name>Siddhant Shrivastava</name></author><id>tag:siddhantsci.org,2015-06-03:blog/2015/06/03/programming-a-mars-rover-week-1/</id><summary type="html">&lt;p&gt;Hi! This is the sixth post in my &lt;a href="http://siddhantsci.org/category/gsoc.html"&gt;GSoC '15 blog series&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;So the much awaited coding period began on 25th May, 2015. After a refreshing &lt;a href="http://siddhantsci.org/blog/2015/05/23/gsoc-15-community-bonding/"&gt;Community Bonding&lt;/a&gt; experience, &lt;a href="http://siddhantsci.org/blog/2015/05/26/workspace-setup-for-telerobotics/"&gt;setting up my workspace&lt;/a&gt;, and &lt;a href="http://siddhantsci.org/blog/2015/05/29/software-architecture-document-for-telerobotics/"&gt;creating a Software Architecture Document&lt;/a&gt; - I was in a position to start coding.&lt;/p&gt;
&lt;h2&gt;Aims and Milestones&lt;/h2&gt;
&lt;p&gt;This week, according to the &lt;a href="http://siddhantsci.org/blog/2015/05/07/gsoc-15-about-my-project/"&gt;timeline&lt;/a&gt;, my aims were -&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Creating the initial set of ROS nodes for the Husky model for linear and angular motion &lt;/li&gt;
&lt;li&gt;Zeroing in on the basic interface for mapping the Kinect bodytracking information and Motivity interface being concurrently developed by Vito to teleoperation commands that Husky can understand&lt;/li&gt;
&lt;li&gt;Figuring out a way to integrate ROS and Tango into ERAS&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So far it has been a good week and I am on schedule. I am able to manipulate the motion of the simulated Husky via an external stimuli.&lt;/p&gt;
&lt;h2&gt;Architecture&lt;/h2&gt;
&lt;p&gt;Before I describe my programs, let me first describe the high-level architecture with help of a simple diagram -&lt;/p&gt;
&lt;p&gt;&lt;img alt="Telerobotics Architecture" src="http://siddhantsci.org/images/arch2.png" /&gt;&lt;/p&gt;
&lt;p&gt;As is evident from the diagram, there are &lt;strong&gt;two distributed systems&lt;/strong&gt; involved - both fairly complicated. These are -&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tango Controls&lt;/li&gt;
&lt;li&gt;ROS (Robot Operating System)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This was by far the &lt;strong&gt;biggest challenge&lt;/strong&gt; of the project. Interfacing data from one distributed system to the other while maintaining low latency and ensuring high performance.&lt;/p&gt;
&lt;p&gt;Another challenge was handling real-time streaming data.
I banged my head against Python Streams. Message brokers like &lt;a href="https://www.rabbitmq.com/"&gt;RabbitMQ&lt;/a&gt; and &lt;a href="http://zeromq.org/"&gt;ZeroMQ&lt;/a&gt;. But as &lt;strong&gt;Albert Einstein&lt;/strong&gt; said -&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If you can't explain it to a six year old, you don't understand it yourself. &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;All this while, I was confused in transferring data over an &lt;strong&gt;additional&lt;/strong&gt; inter-process communication structure between two distributed systems. Meh. Sounds complicated. It actually is. And that is why I chucked that idea out. After spending three full days on this, I realized a &lt;strong&gt;much simpler architecture&lt;/strong&gt; -&lt;/p&gt;
&lt;p&gt;&lt;img alt="ROS and Tango" src="http://siddhantsci.org/images/rostango.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Voila!&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The good thing about this diagram is that it works at scale with as many ROS nodes one may like to add for the rover (Husky) without compromising on the data coming from the Tango bus. The &lt;strong&gt;missing piece&lt;/strong&gt; of the &lt;em&gt;two distributed systems&lt;/em&gt; puzzle is solved by a Tango ROS Node. Now I have a plan to work on in the second week of coding.&lt;/p&gt;
&lt;p&gt;These requirements had to be reflected in the Software Architecture Document as well. To this end, I set up the excellent &lt;a href="https://github.com/timonwong/OmniMarkupPreviewer"&gt;OmniMarkupPreviewer&lt;/a&gt; for &lt;em&gt;Sublime Text&lt;/em&gt; to preview the &lt;strong&gt;reStructuredText&lt;/strong&gt; (&lt;strong&gt;.rst&lt;/strong&gt;) documents that I created.&lt;/p&gt;
&lt;h2&gt;Tryst with ROS and Husky&lt;/h2&gt;
&lt;p&gt;I had never worked with an Unmanned Ground Vehicle before. I did use ROS for robotics experiments at my university lab but needed to quickly jog my memory about ROS programming with &lt;strong&gt;rospy&lt;/strong&gt;. The excellent &lt;a href="http://wiki.ros.org/ROS/Tutorials"&gt;ROS wiki&lt;/a&gt; and the book &lt;strong&gt;ROS By Example&lt;/strong&gt; - &lt;/p&gt;
&lt;p&gt;&lt;img alt="ROS By Example" src="http://siddhantsci.org/images/rbxlogo.png" /&gt;&lt;/p&gt;
&lt;p&gt;It is a haven for robot hobbyists like me and I'll continue to refer to it for time to come.&lt;/p&gt;
&lt;p&gt;Alright, I started my week with ROS programming. My first job was to bring up the simulator and make sure that Husky model responds to commands -&lt;/p&gt;
&lt;p&gt;Husky (and other ROS robots) describes movements in the form of &lt;a href="http://docs.ros.org/api/geometry_msgs/html/msg/Twist.html"&gt;Twist&lt;/a&gt; messages -&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;z&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;where&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt; &lt;span class="n"&gt;is&lt;/span&gt; &lt;span class="n"&gt;linear&lt;/span&gt; &lt;span class="n"&gt;velocity&lt;/span&gt; &lt;span class="n"&gt;along&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt; &lt;span class="n"&gt;axes&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt; &lt;span class="n"&gt;And&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="n"&gt;is&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;angular&lt;/span&gt; &lt;span class="n"&gt;velocity&lt;/span&gt; &lt;span class="n"&gt;about&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt; &lt;span class="n"&gt;axes&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So to move in a circle, we issue [ (5,0,0) , (0,0,2) ]. This would result in a linear speed of 5 in the x direction and angular speed of 2 about the z axis, resulting in a circular motion.&lt;/p&gt;
&lt;p&gt;A simple way to explain the working is to use this command -&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;rostopic&lt;/span&gt; &lt;span class="n"&gt;pub&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;husky_velocity_controller&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;cmd_vel&lt;/span&gt; &lt;span class="n"&gt;geometry_msgs&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;Twist&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt; &lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="sc"&gt;&amp;#39; &amp;#39;&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This publishes a Twist message to the Terminal telling the &lt;strong&gt;/husky_velocity_controller/cmd_vel&lt;/strong&gt; &lt;em&gt;ROS topic&lt;/em&gt; that the &lt;a href="http://docs.ros.org/api/geometry_msgs/html/msg/Twist.html"&gt;Twist&lt;/a&gt; denotes a linear motion of 0.5 m/s along the x direction.&lt;/p&gt;
&lt;p&gt;This is Husky in action -&lt;/p&gt;
&lt;p&gt;&lt;img alt="Husky in action" src="http://siddhantsci.org/images/husky_in_action.png" /&gt;&lt;/p&gt;
&lt;p&gt;To do the same using rospy, the procedure is simple -&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Import the required libraries (to support &lt;em&gt;rospy&lt;/em&gt;, logging, and &lt;em&gt;Twist&lt;/em&gt; messages)&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;import&lt;/span&gt; &lt;span class="n"&gt;roslib&lt;/span&gt;
&lt;span class="n"&gt;import&lt;/span&gt; &lt;span class="n"&gt;rospy&lt;/span&gt;
&lt;span class="n"&gt;from&lt;/span&gt; &lt;span class="n"&gt;geometry_msgs&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;msg&lt;/span&gt; &lt;span class="n"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Twist&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;Set up a ROS node - in this case &lt;strong&gt;move&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;rospy&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;init_node&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;move&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;ROS nodes act as identifiers (source and destination of messages) in the ROS distributed system (modeled as a graph)&lt;/p&gt;
&lt;p&gt;For instance, this is the ROS graph while the Husky is moving about -&lt;/p&gt;
&lt;p&gt;&lt;img alt="ROS Graph" src="http://siddhantsci.org/images/rosgraph.png" /&gt;
This is why ROS scales so well. Any number of publisher and subscriber nodes can be added to extend different applications.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Set up a publisher to the appropriate ROS topic with the ROS message type &lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;rospy&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Publisher&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;husky_velocity_controller&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;cmd_vel&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Twist&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;queue_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The &lt;code&gt;queue_size&lt;/code&gt; argument specifies the message buffer length, and allows for asynchronous transfer of messages on the ROS meesage queue.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Construct a Twist Message&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;twist&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Twist&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;twist&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linear&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;                   
&lt;span class="n"&gt;twist&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linear&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;twist&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linear&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;     
&lt;span class="n"&gt;twist&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;angular&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="n"&gt;twist&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;angular&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;  
&lt;span class="n"&gt;twist&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;angular&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;z&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;    
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;Publish the message&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;publish&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;twist&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;That was easy, isn't it?&lt;/p&gt;
&lt;p&gt;Changing the attributes can allow the Husky to move in a circle and nautilus shape -&lt;/p&gt;
&lt;p&gt;&lt;img alt="Husky Circle" src="http://siddhantsci.org/images/husky_circle.png" /&gt;&lt;/p&gt;
&lt;p&gt;In this way, I proceeded in creating ROS nodes to accept Twist messages from any application and made a small teleoperation program on the lines of the &lt;strong&gt;Arrow&lt;/strong&gt; server in ERAS. With the help of Franco, I set up the Arrow Tango server and obtained the attributes for distance and orientation.&lt;/p&gt;
&lt;p&gt;The next aim is to use the distance and orientation information on the Tango bus and map it to Husky commands so that it may move around appropriately on ground like this -&lt;/p&gt;
&lt;p&gt;&lt;img alt="Husky Nautilus" src="http://siddhantsci.org/images/husky_nautilus.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Random ROS Tidbit&lt;/em&gt; - While working with ROS, I came across this interesting command &lt;code&gt;source&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Why do I call it interesting?&lt;/p&gt;
&lt;p&gt;It does not have a &lt;strong&gt;man-page&lt;/strong&gt;, it does not have a &lt;strong&gt;--help&lt;/strong&gt; or &lt;strong&gt;-h&lt;/strong&gt; argument. It has one simple purpose -&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Execute the content of the file passed as argument &lt;strong&gt;in the current shell&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Note that it is not the same as &lt;strong&gt;./&lt;/strong&gt; which creates a new shell to run the command. Shells are nifty processes which allow other program processes to run. I wrote a shell from scratch for a Network Programming course assignment. You may find it &lt;a href="https://github.com/sidcode/sigshell"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Skype Meeting for Bodytracking&lt;/h2&gt;
&lt;p&gt;Franco, Yuval, Fabio, Ezio, Vito and I had an important meeting on 2nd May( a couple of hours before writing this post). The purpose of the meeting was &lt;strong&gt;Mapping Bodytracking with Telerobotics&lt;/strong&gt;. The whole point of the project is to allow complete virtual and augmented reality immersion of the astronaut and the rover. This is what it means. The robot (a humanoid or a rover) should be able to mimic human action as much as possible. How? If the astronaut runs fast on the Motivity treadmill at a particular angle, the robot should move faster with that angle relative to the moving base position. This would make use of Vito's Kinect-based bodytracking module for determining incremental distance and orientation.&lt;/p&gt;
&lt;p&gt;Since Husky understands velocity in the Twist message, the distance/orientation information must be transformed into linear/angular velocity. I'll be working on it this week. &lt;/p&gt;
&lt;p&gt;Fabio brought up the important aspect of autonomy-control in the robotic system. He pressed upon the need of having three different stimuli to the robot -&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;From the &lt;strong&gt;Bodytracking application&lt;/strong&gt; (external)&lt;/li&gt;
&lt;li&gt;From the &lt;strong&gt;robot's onboard sensors&lt;/strong&gt; (internal)&lt;/li&gt;
&lt;li&gt;From an external source&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This suggestion definitely adds robustness to the entire design, it will help the robot to avoid hitting a rock and override an astronaut's command in case of danger. I will look into it this week and keep semi-autonomy in Telerobotics in mind.&lt;/p&gt;
&lt;p&gt;Yuval talked about contacting the team in Canada which facilitated Husky during V-ERAS 14. The work that I do will be tested on a real Husky eventually. &lt;/p&gt;
&lt;p&gt;Adding a UR10 robotic arm to the Husky to facilitate manipulation and imitation of the human hand was also proposed. I'll look into that after the work on steering is complete.&lt;/p&gt;
&lt;p&gt;In this way, the meeting was &lt;strong&gt;quite important&lt;/strong&gt; and a bunch of &lt;strong&gt;crucial decisions&lt;/strong&gt; regarding &lt;strong&gt;Telerobotics and Bodytracking&lt;/strong&gt; were taken.&lt;/p&gt;
&lt;h2&gt;The Week ahead&lt;/h2&gt;
&lt;p&gt;The following week, we'll have another meeting with all the students and possibly a joint code review session. I will be integrating ROS and Tango and adding support for different levels of Robot control through additional ROS nodes.&lt;/p&gt;
&lt;h2&gt;Summary&lt;/h2&gt;
&lt;p&gt;In hindsight, I was scared my GSoC coding experience would turn out be like this before the start of the &lt;a href=""&gt;Coding period&lt;/a&gt; -&lt;/p&gt;
&lt;p&gt;&lt;img alt="Coding By the Sill" src="http://siddhantsci.org/images/codingbythesill.jpg" /&gt;
Source - &lt;a href="https://www.facebook.com/cluecomics"&gt;CLUE&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;:) In fact I faced nothing like that (but the headphone and the loneliness is true :D ) There were minor setbacks. I had to reinstall ROS as a result of purging my MySQL configuration for Tango. Obviously these were the usual frustrations which crop up with computer programming and Linux, but nothing humongous.
But this is where the &lt;strong&gt;Zen of Python&lt;/strong&gt; kicks in! Using top-notch resources like the &lt;code&gt;logging&lt;/code&gt; module, &lt;code&gt;rqt-graph&lt;/code&gt;, and the inbuilt ROS logger; programming was a breeze. Add to it the awesomeness of Italian Mars Society. I faced a doubt in bodytracking, and six people decided on a Skype call to resolve the issues being faced, and resolve it we did, with gusto.&lt;/p&gt;
&lt;p&gt;The first week was super-hectic. Left with a computer and a programming problem; all-nighters were inevitable. It is proving to be a challenging and fun summer. &lt;/p&gt;
&lt;p&gt;Watch out for my next post in the GSoC 2015 series!&lt;/p&gt;
&lt;p&gt;Ciao!&lt;/p&gt;</summary><category term="GSoC"></category><category term="Python"></category><category term="PSF"></category><category term="computers"></category><category term="science"></category><category term="exploration"></category><category term="space"></category><category term="mars"></category><category term="IMS"></category><category term="Italian Mars Society"></category></entry><entry><title>Software Architecture Document for Telerobotics</title><link href="http://siddhantsci.org/blog/2015/05/29/software-architecture-document-for-telerobotics/" rel="alternate"></link><updated>2015-05-29T00:53:52+00:00</updated><author><name>Siddhant Shrivastava</name></author><id>tag:siddhantsci.org,2015-05-29:blog/2015/05/29/software-architecture-document-for-telerobotics/</id><summary type="html">&lt;h2&gt;The First Three Days&lt;/h2&gt;
&lt;p&gt;Hi! Last couple of days were quite hectic. I am still getting used to the &lt;em&gt;7-hours a day&lt;/em&gt; schedule of GSoC. But the good thing about GSoC is you can adjust the programming schedule according to your own convenience which is one more reason which takes it a notch above other summer coding programs. But I am devoting about 10 hours every day in these initial days to ensure I am well-positioned with respect to my timeline and also keep learning stuff on the go.&lt;/p&gt;
&lt;p&gt;Rants aside, I recently completed the first draft of the Software Architecture Document for my project.&lt;/p&gt;
&lt;h2&gt;Software Architecture Document&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Software Architecture Document&lt;/strong&gt; (quite funnily abbreviated as SAD) is an important (read very) piece of information which entails and ensures what a software project is going to look like when it is built and shipped. I must thank the Italian Mars Society for giving me the much-needed push into the world of Open Source Software Engineering.&lt;/p&gt;
&lt;p&gt;Architecture of any program, especially open-source programs, as described in the excellent book &lt;a href="http://aosabook.org/en/index.html"&gt;Architecture of Open Source Applications&lt;/a&gt; describes software in terms of &lt;strong&gt;different&lt;/strong&gt; layers of abstraction components, depending on who wants to look and improve upon it. Open source applications are a product of efforts of multiple people working on different aspects of a project together. To facilitate effective and non-redundant collaboration with proper version control, a software architecture document comes in handy.&lt;/p&gt;
&lt;p&gt;To put it in one line - &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;SAD ensures all developers, testers, and users are on the same page.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;SAD for Telerobotics Application&lt;/h2&gt;
&lt;p&gt;Take my &lt;strong&gt;Telerobotics application&lt;/strong&gt; for instance. It is made up of three &lt;em&gt;distinct&lt;/em&gt; &lt;strong&gt;features&lt;/strong&gt; or &lt;strong&gt;functional requirements&lt;/strong&gt; - &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Mapping Human body-tracking information to rover motion instructions&lt;/li&gt;
&lt;li&gt;Allowing real-time streaming of the rover's stereo camera-feed to the ERAS application&lt;/li&gt;
&lt;li&gt;Providing an Augmented reality interface obtained from the processing the rover sensor data&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Although I am the only developer working on these aspects currently, I must ensure that the application is in a &lt;strong&gt;well-maintained state&lt;/strong&gt; throughout the life of the project. I must also ensure that a developer with skills in Robotics gets relevant information to the Robotics subsystem of the application (ROS knowledge). I must separate the concerns of a Network Communications developer from the user (the astronaut) while working on Real-time streaming from the rover to the Head Mounted Virtual Reality device.&lt;/p&gt;
&lt;p&gt;While the features describe the expected behaviour of the software system, they require a lot of background machinery which is essential for operation but not relevant for exposing to the end-user. These are &lt;strong&gt;non-functional requirements&lt;/strong&gt;. To give an example, &lt;strong&gt;Robotics Operating System&lt;/strong&gt; is used to manouver the Husky robot around. But the astronaut or the software system need not be concerned that robot communication, control, and command (C3 architecture) takes place using ROS or other robot platforms like YARP or Player/Stage. &lt;/p&gt;
&lt;p&gt;Non-functional requirements in turn are quite important for satisfying the performance requirements of the software system. For instance, the Real-time streaming protocol (RTSP) that I'll be working with soon directly impacts the performance requirement of &lt;strong&gt;Hard-Real Time streaming support.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The Software Architecture Document is generic in that it keeps in mind the evolving technology that may be used to cater to the application in focus. For instance, the &lt;strong&gt;Unmanned Ground Vehicle&lt;/strong&gt; currently being considered is the &lt;strong&gt;Husky rover&lt;/strong&gt;. It is my responsibilty to ensure that the logical layers are independent of the robot being used. The software should be &lt;strong&gt;extensible&lt;/strong&gt; easily to a future ground vehicle that may use an altogether different control architecture than &lt;strong&gt;ROS&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Finally, SAD is practical. It describes the timeline of development of the features.&lt;/p&gt;
&lt;h2&gt;My experience with SADs&lt;/h2&gt;
&lt;p&gt;Working on the SAD has been an immensely edifying experience for me for several reasons -&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;My first foray into Software Engineering literature.&lt;/li&gt;
&lt;li&gt;Learning &lt;em&gt;reStructuredText&lt;/em&gt; as the documentation tool for SAD.&lt;/li&gt;
&lt;li&gt;Appreciating how finely ingrained software-engineering principles are with Programming Language design. For instance, the sections of a SAD directly imbue the features of Object Oriented Programming (abstraction, encapsulation, separation of concern) and Functional Programming (Side effects, Higher-order functions).&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Links to the document&lt;/h2&gt;
&lt;p&gt;If you are interested, the link to my &lt;a href="https://bitbucket.org/italianmarssociety/eras/src/132fff239c3ff892f7cfc8836d3a2921244e444e/servers/telerobotics/doc/?at=default"&gt;software architecture document source is this&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The documentation on readthedocs can be found &lt;a href="eras.readthedocs.org/en/latest/servers/telerobotics/doc/sad.html"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Until my next post on my first week of coding.&lt;/p&gt;
&lt;p&gt;Ciao!&lt;/p&gt;</summary><category term="GSoC"></category><category term="Python"></category><category term="PSF"></category><category term="computers"></category><category term="science"></category><category term="exploration"></category><category term="space"></category><category term="mars"></category><category term="IMS"></category><category term="Italian Mars Society"></category></entry><entry><title>Workspace Setup for Telerobotics</title><link href="http://siddhantsci.org/blog/2015/05/26/workspace-setup-for-telerobotics/" rel="alternate"></link><updated>2015-05-26T00:53:52+00:00</updated><author><name>Siddhant Shrivastava</name></author><id>tag:siddhantsci.org,2015-05-26:blog/2015/05/26/workspace-setup-for-telerobotics/</id><summary type="html">&lt;p&gt;Hi! Yesterday was the start of the &lt;strong&gt;coding period&lt;/strong&gt; which will continue for another 12 weeks. The &lt;a href="http://siddhantsci.org/blog/2015/05/23/gsoc-15-community-bonding/"&gt;Community Bonding period&lt;/a&gt; gave me enough time to install the required packages. This post explains those packages in minimal detail.&lt;/p&gt;
&lt;h2&gt;Project Components&lt;/h2&gt;
&lt;p&gt;My work would heavily require the use of -&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;ROS (Robot Operating System)&lt;/strong&gt; to work with the &lt;a href="www.clearpathrobotics.com/husky/"&gt;Husky Rover&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img alt="ROS Logo" src="http://siddhantsci.org/images/roslogo.png" /&gt;&lt;/p&gt;
&lt;p&gt;ROS is the meta-operating system which is very popular with roboticists. My future posts would describe my work with ROS and the concepts that I am using, in detail.&lt;/p&gt;
&lt;p&gt;More specifically, I am working with ROS Indigo Igloo, which is a LTS (Long-term support) release&lt;/p&gt;
&lt;p&gt;&lt;img alt="Indigo Logo" src="http://siddhantsci.org/images/indigologo.png" /&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Gazebo Simulation environment&lt;/strong&gt; to test the programs written to drive the Husky around&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img alt="Gazebo Logo" src="http://siddhantsci.org/images/gazebologo.png" /&gt;&lt;/p&gt;
&lt;p&gt;I am working with Gazebo version 2.2.3.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Tango-Controls&lt;/strong&gt; Supervisory Control and Data Acquistion system&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If data from different devices is the blood of ERAS, then Tango is the circulatory system. It does an excellent job of handling multiple devices (Motivity treadmill, Kinect Sensors, Blender Game Engine Instances, and in my case a ROS machine with Husky interfaces)&lt;/p&gt;
&lt;p&gt;&lt;img alt="Tango Logo" src="http://siddhantsci.org/images/tangologo.png" /&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Blender Game Engine&lt;/strong&gt; to model the standalone V-ERAS application.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img alt="Blender Logo" src="http://siddhantsci.org/images/blenderlogo.png" /&gt;&lt;/p&gt;
&lt;p&gt;The V-ERAS simulation of the spacecraft looks like this -&lt;/p&gt;
&lt;p&gt;&lt;img alt="V-ERAS simulation" src="http://siddhantsci.org/images/verassim.png" /&gt;&lt;/p&gt;
&lt;p&gt;In the second phase of the project, I will be involved in real-time streaming of rover stereo camera feed to the displays in the V-ERAS simulation.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Python&lt;/strong&gt; (of course :D )&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img alt="Python Logo" src="http://siddhantsci.org/blog/2015/05/26/workspace-setup-for-telerobotics/images/python-logo.png" /&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Ubuntu 14.04 (Trusty Tahr)&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;ROS Indigo offers complete support for this version of Ubuntu.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Ubuntu Logo" src="http://siddhantsci.org/blog/2015/05/26/workspace-setup-for-telerobotics/images/ubuntulogo.png" /&gt;&lt;/p&gt;
&lt;h2&gt;Screenshots&lt;/h2&gt;
&lt;p&gt;To Python-ify my experience even further, I installed &lt;strong&gt;Terminator&lt;/strong&gt;, a Python-based program which makes terminal arrangement as flexible as humanly possible on Linux.&lt;/p&gt;
&lt;p&gt;Working with ROS requires opening up a lot of terminal  and Terminator makes this hassle-free.&lt;/p&gt;
&lt;p&gt;Take a look for yourselves -&lt;/p&gt;
&lt;p&gt;&lt;img alt="Terminator" src="http://siddhantsci.org/blog/2015/05/26/workspace-setup-for-telerobotics/images/terminator.png" /&gt;&lt;/p&gt;
&lt;p&gt;I am using different text editors for different purposes.&lt;/p&gt;
&lt;p&gt;While working with &lt;strong&gt;Markdown&lt;/strong&gt; and &lt;strong&gt;reStructuredText&lt;/strong&gt;, I use Sublime Text.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Sublime Text Logo" src="http://siddhantsci.org/blog/2015/05/26/workspace-setup-for-telerobotics/images/sublimelogo.png" /&gt;&lt;/p&gt;
&lt;p&gt;Vim is my editor of choice for all things Python. I have been using it for open-source development since last year.&lt;/p&gt;
&lt;p&gt;So, with this I wrap up this setup post.&lt;/p&gt;
&lt;p&gt;Just for kicks, this is what my desktop looks like -&lt;/p&gt;
&lt;p&gt;&lt;img alt="Desktop IMS" src="http://siddhantsci.org/blog/2015/05/26/workspace-setup-for-telerobotics/images/desktop.png" /&gt;&lt;/p&gt;
&lt;p&gt;I must admit it keeps me motivated to design software for Mars missions. Just in case you're wondering, the theme I use is the MacBuntu theme. It is pretty distraction-free.&lt;/p&gt;
&lt;h2&gt;To Coding and beyond!&lt;/h2&gt;</summary><category term="GSoC"></category><category term="Python"></category><category term="PSF"></category><category term="computers"></category><category term="science"></category><category term="exploration"></category><category term="space"></category><category term="mars"></category><category term="IMS"></category><category term="Italian Mars Society"></category></entry><entry><title>GSoC '15 Community Bonding</title><link href="http://siddhantsci.org/blog/2015/05/23/gsoc-15-community-bonding/" rel="alternate"></link><updated>2015-05-23T00:53:52+00:00</updated><author><name>Siddhant Shrivastava</name></author><id>tag:siddhantsci.org,2015-05-23:blog/2015/05/23/gsoc-15-community-bonding/</id><summary type="html">&lt;p&gt;Third Post in the GSoC 2015 series. Here I'll take you through the engaging community bonding experience.&lt;/p&gt;
&lt;h2&gt;Introduction to Community Bonding&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Community Bonding&lt;/strong&gt; is arguably one of the most important phases of the Google Summer of Code. In the 2015 edition, it took place from April 27 to May 25. This is what the &lt;a href="http://www.google-melange.com/gsoc/document/show/gsoc_program/google/gsoc2015/help_page"&gt;GSoC FAQ&lt;/a&gt; has to say about this period -&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Students get to know mentors, read documentation, get up to speed to begin working on their projects.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;About the community&lt;/h2&gt;
&lt;p&gt;&lt;img alt="ERAS logo" src="http://siddhantsci.org/blog/2015/05/23/gsoc-15-community-bonding/images/eras-logo.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;Italian Mars Society&lt;/strong&gt; is a highly motivated group of incredibly smart and friendly scientists and developers who share the vision of working towards manned missions to Mars. I have been interacting with the community since March 2015 and I've never looked back. I was interested in the projects even during the brief period when it was unclear whether IMS would be able to participate or not. I'm grateful to the community members for applying under the Python Software Foundation umbrella and giving students like me a brilliant opportunity to explore real world Open Source development. From what I've heard, this organization comes up with the &lt;em&gt;coolest&lt;/em&gt; projects for GSoC. And I concur with them - my project seems to blend in all the cool fields required for exploration - Robotics, Body-tracking, Virtual Reality, Oculus Rift, Real-time 3-D video streaming, Augmented Reality, etc.&lt;/p&gt;
&lt;h2&gt;Understanding the Codebase&lt;/h2&gt;
&lt;p&gt;&lt;img alt="Mercurial logo" src="http://siddhantsci.org/blog/2015/05/23/gsoc-15-community-bonding/images/mercurial.png" /&gt;&lt;/p&gt;
&lt;p&gt;To this end, there is a stable amount of software/hardware development shared on the Bitbucket platform. While interacting with Franco and Ezio, I discovered that all students are given &lt;strong&gt;write access&lt;/strong&gt; to the &lt;a href="https://bitbucket.org/italianmarssociety/eras/"&gt;ERAS&lt;/a&gt; and &lt;a href="https://bitbucket.org/italianmarssociety/v-eras-blender"&gt;V-ERAS&lt;/a&gt; repositories using the &lt;strong&gt;Mercurial&lt;/strong&gt; revision control system. This imparts tremendous responsiblity as new developers which I very much appreciate since it fosters trust and makes us mature community members. &lt;/p&gt;
&lt;p&gt;Going through the codebase a couple of weeks ago, I found well-documented code, almost all of which follows the PEP8 guidelines and written in Python 3. The heart of the V-ERAS project is the &lt;a href="http://www.tango-controls.org/"&gt;Tango Controls&lt;/a&gt; server which is a distributed device server for Supervisory Control and Data Acquistion systems. This is ideal for a complex environment like ERAS where multiple hardware and software devices like the Oculus VR, Kinect, Linux Machines, Husky Rover, and Blender Game Engine applications are involved in a distributed setup. The entire networking subsystem of ERAS is well-explained in &lt;a href="http://erasproject.org/download/the-networking-sub-system-of-t-he-virtual-european-mar-s-analog-station-e-melotti-bachelors-thesis/"&gt;Ezio's thesis&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Interacting with the Community&lt;/h2&gt;
&lt;p&gt;My experience with the Italian Mars Society has been memorable and pleasant right from the word go when I first entered the hallowed &lt;strong&gt;IMS&lt;/strong&gt; channel of IRC (Internet Relay Chat) and introduced myself. I was promptly pointed to the right person for my project of interest. Within a single IRC Chat session with Franco, I got a clear idea of what to expect from this GSoC. The IRC channel though frequented by a small number of people is always bustling with activity. We've had fruitful discussion for each and every part of the project - from software architecture diagrams in the proposal, to the collaboration between two GSoC projects, and even some fun interactions about Python software development and Mars exploration. I always appreciate the levels of responsibity and feedback that the community members muster during interacting with students. Helping my fellow GSoC aspirants and seeking help from them is always a refreshing experience. Apart from IRC and Email, I got the chance to &lt;strong&gt;video-conference&lt;/strong&gt; with all the project mentors on two occasions - &lt;em&gt;during my GSoC interview and in the Kickoff meeting after the GSoC selection&lt;/em&gt;. This was the first time I had a teleconference interview and I thank IMS for that. It felt more like a sincere discussion of the things that I had in mind for the GSoC project rather than a test of my skills. The trust these guys had in me let me confidently speak out my mind which helped me make my points. The big GSoC Kickoff meeting meetup took place on April 29, 2015 where we all gathered on &lt;strong&gt;Google Hangouts&lt;/strong&gt; to discuss various important points for the upcoming summer of code such as -&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The importance of blogging&lt;/li&gt;
&lt;li&gt;Hardware/Software requirements&lt;/li&gt;
&lt;li&gt;Strategic timeline of events&lt;/li&gt;
&lt;li&gt;Software engineering guidelines&lt;/li&gt;
&lt;li&gt;Suggestions of joint code review sessions&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I helped prepare the meeting minutes for this session since some members faced connection problems to join the Hangout. These are shared in &lt;a href="https://docs.google.com/document/d/1jRhBnmjlMINCjwuomrE18BPTKnUO8974-I9qexb5TfQ/edit?usp=sharing"&gt;this document&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Setup and Technologies&lt;/h2&gt;
&lt;p&gt;&lt;img alt="Husky Rover" src="http://siddhantsci.org/blog/2015/05/23/gsoc-15-community-bonding/images/husky1.jpe" /&gt;&lt;/p&gt;
&lt;p&gt;I have been exposed to an ample number of new concepts and technologies with this project. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Terrain Vehicle Rover&lt;/strong&gt; - Clearpath Robotics' &lt;strong&gt;Husky robot&lt;/strong&gt; which is ROS-based&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Microsoft Kinect Sensor&lt;/strong&gt; for obtaining body-tracking information&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Minoru 3-d webcam&lt;/strong&gt; for stereo video streaming&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Oculus Rift Development Kit 2&lt;/strong&gt; for augmented reality applications&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To this end, I set up my workstation for the &lt;a href="https://docs.google.com/document/d/11iE-pQ8wEX8BUwbexGgULJddv0xWRN98MYRrd0iunOI/edit?usp=sharing"&gt;project requirements&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;My current machine configuration for this GSoC project is as follows:&lt;/p&gt;
&lt;p&gt;-Ubuntu 14.04.2 (Trusty Tahr)
-ROS Indigo
-Python 3
-Blender 2.74
-Tango Controls 1.99
-Linux Kernel 3.2
-Mercurial 3.4
-Hardware: 8 GB RAM, Intel Core i7 processor, Nvidia 2GB GPU GT650M&lt;/p&gt;
&lt;p&gt;In the last couple of weeks, I have been busy with setting up the various ROS packages which are required for &lt;em&gt;bodytracking based semi-autonmous teleoperation&lt;/em&gt;. The list of ROS packages will be added to the project documentation soon.&lt;/p&gt;
&lt;h2&gt;Learning Experience so far&lt;/h2&gt;
&lt;p&gt;&lt;img alt="ffmpeg" src="http://siddhantsci.org/blog/2015/05/23/gsoc-15-community-bonding/images/ffmpeg.png" /&gt;&lt;/p&gt;
&lt;p&gt;I've learnt an unexpected great deal about a lot of different things during this project. I had to do a lot of reading to get up to speed with the existing state of V-ERAS. Franco pointed me to the &lt;a href="https://eras.readthedocs.org/en/latest/index.html"&gt;project documentation pages&lt;/a&gt;. I learned about Blender and Blender Game Engine after pulling an all-nighter. FFMPEG followed soon after that where I had to set up a MJPEG streaming server for the BGE client. That was followed by my first experience with PEP8, Mercurial, architecture diagrams, Tango Control system. My GSoC proposal has been an extensive piece of work with 61 revisions and brilliant feedback from my mentors. The proposal can be found &lt;a href="http://erasproject.org/2015-gsoc/#2"&gt;here&lt;/a&gt;. A more comprehensive description of the project is taken up in &lt;a href="gsoc-02-project-details.md"&gt;this post&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;To be continued...about ROS, Software Testing, Mapping, algorithms, etc&lt;/em&gt;&lt;/p&gt;</summary><category term="GSoC"></category><category term="Python"></category><category term="PSF"></category><category term="computers"></category><category term="science"></category><category term="exploration"></category><category term="space"></category><category term="mars"></category></entry><entry><title>GSoC '15 - About my Project</title><link href="http://siddhantsci.org/blog/2015/05/07/gsoc-15-about-my-project/" rel="alternate"></link><updated>2015-05-07T00:53:52+00:00</updated><author><name>Siddhant Shrivastava</name></author><id>tag:siddhantsci.org,2015-05-07:blog/2015/05/07/gsoc-15-about-my-project/</id><summary type="html">&lt;p&gt;Second Post in the GSoC 2015 series. This post is intended to explain my project proposal.&lt;/p&gt;
&lt;p&gt;The project proposal that I submitted can be found &lt;a href="http://erasproject.org/2015-gsoc/#2"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img alt="ERAS Station" src="http://siddhantsci.org/blog/2015/05/07/gsoc-15-about-my-project/images/eras-station.jpg" /&gt;
&lt;em&gt;to be continued...&lt;/em&gt;&lt;/p&gt;</summary><category term="GSoC"></category><category term="Python"></category><category term="PSF"></category><category term="computers"></category><category term="science"></category><category term="exploration"></category><category term="space"></category><category term="mars"></category></entry><entry><title>GSoC 2015 with the Italian Mars Society</title><link href="http://siddhantsci.org/blog/2015/04/29/gsoc-2015-with-the-italian-mars-society/" rel="alternate"></link><updated>2015-04-29T00:53:52+00:00</updated><author><name>Siddhant Shrivastava</name></author><id>tag:siddhantsci.org,2015-04-29:blog/2015/04/29/gsoc-2015-with-the-italian-mars-society/</id><summary type="html">&lt;p&gt;&lt;img alt="GSoC Banner" src="http://siddhantsci.org/images/gsoc-banner.png" /&gt;&lt;/p&gt;
&lt;p&gt;I got accepted into the eleventh edition of the &lt;strong&gt;Google Summer of Code&lt;/strong&gt; program (&lt;a href="http://www.google-melange.com/gsoc/homepage/google/gsoc2015"&gt;GSoC 2015&lt;/a&gt;) with the &lt;strong&gt;Python Software Foundation&lt;/strong&gt; umbrella organization. The list of selected students was announced on 28th April, 2015.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Python Logo" src="http://siddhantsci.org/blog/2015/05/26/workspace-setup-for-telerobotics/images/python-logo.png" /&gt;&lt;/p&gt;
&lt;p&gt;More specifically, I'll be working with the Italian Mars Society under the ERAS (European MaRs Analogue Station) project. 
Quoting from the &lt;a href="http://erasproject.org/"&gt;source&lt;/a&gt; -&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The European MaRs Analogue Station for Advanced Technologies Integration (ERAS) is a program spearheaded by the Italian Mars Society (IMS) which main goal is to provide an effective test bed for field operation studies in preparation for manned missions to Mars.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img alt="ERAS logo" src="http://siddhantsci.org/blog/2015/05/23/gsoc-15-community-bonding/images/eras-logo.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;The focus of this GSoC project is &lt;strong&gt;Virtual Reality based Telerobotics&lt;/strong&gt; for V-ERAS.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Virtual European Mars Analog Station (V-ERAS)&lt;/strong&gt; is based on immersive real-time environment simulations running on top of the Blender Game Engine (BGE).&lt;/p&gt;
&lt;p&gt;This project has three distinct components - &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;A &lt;strong&gt;ROS-Kinect&lt;/strong&gt; interface for the Teleoperative control of the Clearpath Husky Robot rover's motion via human body-tracking.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Streaming the 3-D stereo camera video feed&lt;/strong&gt; from the rover to BGE over the network.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Processing the video feed into an &lt;strong&gt;Augmented Reality&lt;/strong&gt; experience through a &lt;strong&gt;head-mounted Virtual Reality device&lt;/strong&gt;. &lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The goal of this V-ERAS project is thus to develop a software and hardware system that enhances the capabilities of the crew members preparing for Mars missions.&lt;/p&gt;
&lt;p&gt;I feel elated to be a part of the Italian Mars Society and be able to contribute towards manned space exploration which is one of the vital aims of the next two decades. GSoC marks my first foray into the world of collaborative Open Source software development.&lt;/p&gt;
&lt;p&gt;I shall be mentored by two really cool people - &lt;a href="https://il.linkedin.com/in/yuvalbrodsky"&gt;Yuval Brodsky&lt;/a&gt; and &lt;a href="https://plus.google.com/105053384149339279492/posts"&gt;Fabio Nigi&lt;/a&gt; with whom I share my interests in space exploration, robotics, networks, and free software. In addition, I'll be constantly interacting with the IMS-ERAS community - &lt;a href="in.linkedin.com/pub/franco-carbognani/3/998/145"&gt;Franco Carbognani&lt;/a&gt;, Ezio Melotti, Mario Tambos, Ambar Mehrotra, Shridhar Mishra, Vito Gentile. &lt;/p&gt;
&lt;p&gt;Thank you Google for this unique birthday gift :)&lt;/p&gt;
&lt;p&gt;Looking forward to a great and challenging summer of Code!&lt;/p&gt;
&lt;p&gt;I'll share the details of the project in the next post in this series.&lt;/p&gt;</summary><category term="GSoC"></category><category term="Python"></category><category term="PSF"></category><category term="computers"></category><category term="science"></category><category term="exploration"></category><category term="space"></category><category term="mars"></category></entry><entry><title>GSoC RSS Feed Test Post</title><link href="http://siddhantsci.org/blog/2015/04/16/gsoc-rss-feed-test-post/" rel="alternate"></link><updated>2015-04-16T18:10:52+05:30</updated><author><name>Siddhant Shrivastava</name></author><id>tag:siddhantsci.org,2015-04-16:blog/2015/04/16/gsoc-rss-feed-test-post/</id><summary type="html">&lt;p&gt;Much GSoC. So RSS. Very Python :)&lt;/p&gt;
&lt;p&gt;This is a test blog post to check if the &lt;strong&gt;atom.xml&lt;/strong&gt; for the category &lt;strong&gt;GSoC&lt;/strong&gt; works or not. Python Software Foundation motivates its students to blog at least once in every two weeks (stating the frequency of posting in clear terms because biweekly can be ambiguous sometimes). &lt;/p&gt;
&lt;p&gt;Blogging the &lt;strong&gt;developments&lt;/strong&gt; is essential for any constructive task; in my case the task is Open Source Software development using Python.&lt;/p&gt;
&lt;h2&gt;Why Blog?&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Developments entail success, setbacks(interestingly &lt;em&gt;failure&lt;/em&gt; is not used in this industry because nobody ever fails), issues, progress, discussion on design aspects and learning.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;Update(29th April, 2015)&lt;/h2&gt;
&lt;p&gt;The list of accepted students was announced yesterday(amazingly coinciding with my birthday). I have been accepted for the Google Summer of Code program as a student under the Python Software Foundation umbrella with the organization - Italian Mars Society. A detailed post on my acceptance can be found here.&lt;/p&gt;</summary><category term="GSoC"></category><category term="Python"></category><category term="PSF"></category></entry></feed>